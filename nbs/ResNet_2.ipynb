{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Copied and modified from Rodney Thomas' posted version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: GeForce GTX 1080 (CNMeM is disabled, cuDNN 5110)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import six\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import glob\n",
    "import random\n",
    "\n",
    "from os.path import join\n",
    "\n",
    "np.random.seed(2016)\n",
    "random.seed(2016)\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Activation, merge, Dense, Flatten, Lambda\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.callbacks import Callback, LearningRateScheduler\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ReduceLROnPlateau, CSVLogger, EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Removes autoscroll throughout process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
       "    return false;\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Residual Network Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def _bn_relu(input):\n",
    "    \"\"\"Helper to build a BN -> relu block\n",
    "    \"\"\"\n",
    "    norm = BatchNormalization(axis=CHANNEL_AXIS)(input)\n",
    "    return Activation(\"relu\")(norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def _conv_bn_relu(**conv_params):\n",
    "    \"\"\"Helper to build a conv -> BN -> relu block\n",
    "    \"\"\"\n",
    "    nb_filter = conv_params[\"nb_filter\"]\n",
    "    nb_row = conv_params[\"nb_row\"]\n",
    "    nb_col = conv_params[\"nb_col\"]\n",
    "    subsample = conv_params.setdefault(\"subsample\", (1, 1))\n",
    "    init = conv_params.setdefault(\"init\", \"he_normal\")\n",
    "    border_mode = conv_params.setdefault(\"border_mode\", \"same\")\n",
    "    W_regularizer = conv_params.setdefault(\"W_regularizer\", l2(1.e-4))\n",
    "\n",
    "    def f(input):\n",
    "        conv = Convolution2D(nb_filter=nb_filter, nb_row=nb_row, nb_col=nb_col, subsample=subsample,\n",
    "                             init=init, border_mode=border_mode, W_regularizer=W_regularizer)(input)\n",
    "        return _bn_relu(conv)\n",
    "\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def _bn_relu_conv(**conv_params):\n",
    "    \"\"\"Helper to build a BN -> relu -> conv block.\n",
    "    This is an improved scheme proposed in http://arxiv.org/pdf/1603.05027v2.pdf\n",
    "    \"\"\"\n",
    "    nb_filter = conv_params[\"nb_filter\"]\n",
    "    nb_row = conv_params[\"nb_row\"]\n",
    "    nb_col = conv_params[\"nb_col\"]\n",
    "    subsample = conv_params.setdefault(\"subsample\", (1,1))\n",
    "    init = conv_params.setdefault(\"init\", \"he_normal\")\n",
    "    border_mode = conv_params.setdefault(\"border_mode\", \"same\")\n",
    "    W_regularizer = conv_params.setdefault(\"W_regularizer\", l2(1.e-4))\n",
    "\n",
    "    def f(input):\n",
    "        activation = _bn_relu(input)\n",
    "        return Convolution2D(nb_filter=nb_filter, nb_row=nb_row, nb_col=nb_col, subsample=subsample,\n",
    "                             init=init, border_mode=border_mode, W_regularizer=W_regularizer)(activation)\n",
    "\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def _shortcut(input, residual):\n",
    "    \"\"\"Adds a shortcut between input and residual block and merges them with \"sum\"\n",
    "    \"\"\"\n",
    "    # Expand channels of shortcut to match residual.\n",
    "    # Stride appropriately to match residual (width, height)\n",
    "    # Should be int if network architecture is correctly configured.\n",
    "    input_shape = K.int_shape(input)\n",
    "    residual_shape = K.int_shape(residual)\n",
    "    stride_width = int(round(input_shape[ROW_AXIS] / residual_shape[ROW_AXIS]))\n",
    "    stride_height = int(round(input_shape[COL_AXIS] / residual_shape[COL_AXIS]))\n",
    "    equal_channels = input_shape[CHANNEL_AXIS] == residual_shape[CHANNEL_AXIS]\n",
    "\n",
    "    shortcut = input\n",
    "    # 1 X 1 conv if shape is different. Else identity.\n",
    "    if stride_width > 1 or stride_height > 1 or not equal_channels:\n",
    "        shortcut = Convolution2D(nb_filter=residual_shape[CHANNEL_AXIS],\n",
    "                                 nb_row=1, nb_col=1,\n",
    "                                 subsample=(stride_width, stride_height),\n",
    "                                 init=\"he_normal\", border_mode=\"valid\",\n",
    "                                 W_regularizer=l2(0.0001))(input)\n",
    "\n",
    "    return merge([shortcut, residual], mode=\"sum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def _residual_block(block_function, nb_filter, repetitions, is_first_layer=False):\n",
    "    \"\"\"Builds a residual block with repeating bottleneck blocks.\n",
    "    \"\"\"\n",
    "    def f(input):\n",
    "        for i in range(repetitions):\n",
    "            init_subsample = (1, 1)\n",
    "            if i == 0 and not is_first_layer:\n",
    "                init_subsample = (2, 2)\n",
    "            input = block_function(nb_filter=nb_filter, init_subsample=init_subsample,\n",
    "                                   is_first_block_of_first_layer=(is_first_layer and i == 0))(input)\n",
    "        return input\n",
    "\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def basic_block(nb_filter, init_subsample=(1, 1), is_first_block_of_first_layer=False):\n",
    "    \"\"\"Basic 3 X 3 convolution blocks for use on resnets with layers <= 34.\n",
    "    Follows improved proposed scheme in http://arxiv.org/pdf/1603.05027v2.pdf\n",
    "    \"\"\"\n",
    "    def f(input):\n",
    "\n",
    "        if is_first_block_of_first_layer:\n",
    "            # don't repeat bn->relu since we just did bn->relu->maxpool\n",
    "            conv1 = Convolution2D(nb_filter=nb_filter,\n",
    "                                 nb_row=3, nb_col=3,\n",
    "                                 subsample=init_subsample,\n",
    "                                 init=\"he_normal\", border_mode=\"same\",\n",
    "                                 W_regularizer=l2(0.0001))(input)\n",
    "        else:\n",
    "            conv1 = _bn_relu_conv(nb_filter=nb_filter, nb_row=3, nb_col=3,\n",
    "                                  subsample=init_subsample)(input)\n",
    "\n",
    "        residual = _bn_relu_conv(nb_filter=nb_filter, nb_row=3, nb_col=3)(conv1)\n",
    "        return _shortcut(input, residual)\n",
    "\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def bottleneck(nb_filter, init_subsample=(1, 1), is_first_block_of_first_layer=False):\n",
    "    \"\"\"Bottleneck architecture for > 34 layer resnet.\n",
    "    Follows improved proposed scheme in http://arxiv.org/pdf/1603.05027v2.pdf\n",
    "\n",
    "    Returns:\n",
    "        A final conv layer of nb_filter * 4\n",
    "    \"\"\"\n",
    "    def f(input):\n",
    "\n",
    "        if is_first_block_of_first_layer:\n",
    "            # don't repeat bn->relu since we just did bn->relu->maxpool\n",
    "            conv_1_1 = Convolution2D(nb_filter=nb_filter,\n",
    "                                 nb_row=1, nb_col=1,\n",
    "                                 subsample=init_subsample,\n",
    "                                 init=\"he_normal\", border_mode=\"same\",\n",
    "                                 W_regularizer=l2(0.0001))(input)\n",
    "        else:\n",
    "            conv_1_1 = _bn_relu_conv(nb_filter=nb_filter, nb_row=1, nb_col=1,\n",
    "                                     subsample=init_subsample)(input)\n",
    "\n",
    "        conv_3_3 = _bn_relu_conv(nb_filter=nb_filter, nb_row=3, nb_col=3)(conv_1_1)\n",
    "        residual = _bn_relu_conv(nb_filter=nb_filter * 4, nb_row=1, nb_col=1)(conv_3_3)\n",
    "        return _shortcut(input, residual)\n",
    "\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def _handle_dim_ordering():\n",
    "    global ROW_AXIS\n",
    "    global COL_AXIS\n",
    "    global CHANNEL_AXIS\n",
    "    if K.image_dim_ordering() == 'tf':\n",
    "        ROW_AXIS = 1\n",
    "        COL_AXIS = 2\n",
    "        CHANNEL_AXIS = 3\n",
    "    else:\n",
    "        CHANNEL_AXIS = 1\n",
    "        ROW_AXIS = 2\n",
    "        COL_AXIS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def _get_block(identifier):\n",
    "    if isinstance(identifier, six.string_types):\n",
    "        res = globals().get(identifier)\n",
    "        if not res:\n",
    "            raise ValueError('Invalid {}'.format(identifier))\n",
    "        return res\n",
    "    return identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class ResnetBuilder(object):\n",
    "    @staticmethod\n",
    "    def build(input_shape, num_outputs, block_fn, repetitions):\n",
    "        \"\"\"Builds a custom ResNet like architecture.\n",
    "\n",
    "        Args:\n",
    "            input_shape: The input shape in the form (nb_channels, nb_rows, nb_cols)\n",
    "            num_outputs: The number of outputs at final softmax layer\n",
    "            block_fn: The block function to use. This is either `basic_block` or `bottleneck`.\n",
    "                The original paper used basic_block for layers < 50\n",
    "            repetitions: Number of repetitions of various block units.\n",
    "                At each block unit, the number of filters are doubled and the input size is halved\n",
    "\n",
    "        Returns:\n",
    "            The keras `Model`.\n",
    "        \"\"\"\n",
    "        _handle_dim_ordering()\n",
    "        if len(input_shape) != 3:\n",
    "            raise Exception(\"Input shape should be a tuple (nb_channels, nb_rows, nb_cols)\")\n",
    "\n",
    "        # Permute dimension order if necessary\n",
    "        if K.image_dim_ordering() == 'tf':\n",
    "            input_shape = (input_shape[1], input_shape[2], input_shape[0])\n",
    "\n",
    "        # Load function from str if needed.\n",
    "        block_fn = _get_block(block_fn)\n",
    "\n",
    "        input = Input(shape=input_shape)\n",
    "        conv1 = _conv_bn_relu(nb_filter=64, nb_row=7, nb_col=7, subsample=(2, 2))(input)\n",
    "        pool1 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), border_mode=\"same\")(conv1)\n",
    "\n",
    "        block = pool1\n",
    "        nb_filter = 64\n",
    "        for i, r in enumerate(repetitions):\n",
    "            block = _residual_block(block_fn, nb_filter=nb_filter, repetitions=r, is_first_layer=(i == 0))(block)\n",
    "            nb_filter *= 2\n",
    "\n",
    "        # Last activation\n",
    "        block = _bn_relu(block)\n",
    "\n",
    "        block_norm = BatchNormalization(mode=0, axis=CHANNEL_AXIS)(block)\n",
    "        block_output = Activation(\"relu\")(block_norm)\n",
    "\n",
    "        # Classifier block\n",
    "        block_shape = K.int_shape(block)\n",
    "        pool2 = AveragePooling2D(pool_size=(block_shape[ROW_AXIS], block_shape[COL_AXIS]),\n",
    "                                 strides=(1, 1))(block_output)\n",
    "        flatten1 = Flatten()(pool2)\n",
    "        dense = Dense(output_dim=num_outputs, init=\"he_normal\", activation=\"softmax\")(flatten1)\n",
    "        #dense = Dense(output_dim=num_outputs, W_regularizer=l2(0.01), init=\"he_normal\", activation=\"linear\")(flatten1)\n",
    "\n",
    "        model = Model(input=input, output=dense)\n",
    "        return model\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_test(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, basic_block, [1, 1, 1, 1])\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_18(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, basic_block, [2, 2, 2, 2])\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_34(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, basic_block, [3, 4, 6, 3])\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_50(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 4, 6, 3])\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_101(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 4, 23, 3])\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_152(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 8, 36, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Global Declarations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "conf = dict()\n",
    "\n",
    "# How many patients will be in train and validation set during training. Range: (0; 1)\n",
    "conf['train_valid_fraction'] = 0.75\n",
    "\n",
    "# Batch size for CNN [Depends on GPU and memory available]\n",
    "conf['num_layers'] = 18\n",
    "conf['batch_size'] = 120\n",
    "\n",
    "# Number of epochs for CNN training\n",
    "conf['nb_epoch'] = 1000\n",
    "\n",
    "# Early stopping. Stop training after epochs without improving on validation\n",
    "conf['stop_patience'] = 100\n",
    "conf['lr_patience'] = 50\n",
    "\n",
    "# Shape of image for CNN (Larger the better, but you need to increase CNN as well)\n",
    "#conf['image_shape'] = (4160,4128)\n",
    "#conf['image_shape'] = (2080,2064)\n",
    "#conf['image_shape'] = (1024,1024)\n",
    "conf['image_shape'] = (192,192)\n",
    "\n",
    "conf['data_augmentation'] = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Batch Generator for model fit_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def batch_generator_train(files, batch_size):\n",
    "    number_of_batches = np.ceil(len(files)/batch_size)\n",
    "    counter = 0\n",
    "    random.shuffle(files)\n",
    "    while True:\n",
    "        batch_files = files[batch_size*counter:batch_size*(counter+1)]\n",
    "        image_list = []\n",
    "        mask_list = []\n",
    "        for f in batch_files:\n",
    "            image = cv2.imread(f)\n",
    "            image = cv2.resize(image, conf['image_shape'])\n",
    "\n",
    "            if \"Type_1\" in f:\n",
    "                mask = [1, 0, 0]\n",
    "            elif \"Type_2\" in f:\n",
    "                mask = [0, 1, 0]\n",
    "            elif \"Type_3\" in f:\n",
    "                mask = [0, 0, 1]\n",
    "            else:\n",
    "                raise RuntimeError(\"Bad file name, couldn't determine cancer type\")\n",
    "\n",
    "            image_list.append(image)\n",
    "            mask_list.append(mask)\n",
    "        counter += 1\n",
    "        image_list = np.array(image_list)\n",
    "        mask_list = np.array(mask_list)\n",
    "\n",
    "        yield image_list, mask_list\n",
    "\n",
    "        if counter == number_of_batches:\n",
    "            random.shuffle(files)\n",
    "            counter = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Hardcoded paths to training files. Note that \"additional\" has been renamed to \"add01\" since the path lengths must be the same for substring extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# file paths to training and additional samples\n",
    "gFilesBase = \"../data/preprocess1\"\n",
    "filepaths = []\n",
    "filepaths.append( join(gFilesBase, \"train/Type_1/\") )\n",
    "filepaths.append( join(gFilesBase, \"train/Type_2/\") )\n",
    "filepaths.append( join(gFilesBase, \"train/Type_3/\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "filepaths.append( join(gFilesBase, \"additional/AType_1/\") )\n",
    "filepaths.append( join(gFilesBase, \"additional/AType_2/\") )\n",
    "filepaths.append( join(gFilesBase, \"additional/AType_3/\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Get a list of all training files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1481\n"
     ]
    }
   ],
   "source": [
    "allFiles = []\n",
    "\n",
    "for i, filepath in enumerate(filepaths):\n",
    "    files = glob.glob(filepath + '*.jpg')\n",
    "    allFiles = allFiles + files\n",
    "\n",
    "print(len(allFiles))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Split data into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train patients: 1111\n",
      "Valid patients: 370\n"
     ]
    }
   ],
   "source": [
    "split_point = int(round(conf['train_valid_fraction']*len(allFiles)))\n",
    "\n",
    "random.shuffle(allFiles)\n",
    "\n",
    "train_list = allFiles[:split_point]\n",
    "valid_list = allFiles[split_point:]\n",
    "print('Train patients: {}'.format(len(train_list)))\n",
    "print('Valid patients: {}'.format(len(valid_list)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def batch_generator_train2(files):\n",
    "    random.shuffle(files)\n",
    "    image_list = []\n",
    "    mask_list = []\n",
    "    for f in files:\n",
    "        image = cv2.imread(f)\n",
    "        image = cv2.resize(image, conf['image_shape'])\n",
    "\n",
    "        if \"Type_1\" in f:\n",
    "            mask = [1, 0, 0]\n",
    "        elif \"Type_2\" in f:\n",
    "            mask = [0, 1, 0]\n",
    "        elif \"Type_3\" in f:\n",
    "            mask = [0, 0, 1]\n",
    "        else:\n",
    "            raise RuntimeError(\"Bad file name, couldn't determine cancer type\")\n",
    "\n",
    "        image_list.append(image)\n",
    "        mask_list.append(mask)\n",
    "\n",
    "    image_list = np.array(image_list)\n",
    "    mask_list = np.array(mask_list)\n",
    "    return (image_list, mask_list)\n",
    "\n",
    "def GetDataFromFileLists(trainList, validList):\n",
    "    (X_train, Y_train) = batch_generator_train2(trainList)\n",
    "    (X_valid, Y_valid) = batch_generator_train2(validList)\n",
    "    return (X_train, Y_train), (X_valid, Y_valid)\n",
    "            \n",
    "           \n",
    "(X_train, Y_train), (X_valid, Y_valid) = GetDataFromFileLists(train_list, valid_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Testing model generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create and compile model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matt/Envs/keras/lib/python2.7/site-packages/ipykernel/__main__.py:14: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_initializer=\"he_normal\", padding=\"same\", strides=(2, 2), kernel_regularizer=<keras.reg..., filters=64, kernel_size=(7, 7))`\n",
      "/home/matt/Envs/keras/lib/python2.7/site-packages/ipykernel/__main__.py:30: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(padding=\"same\", strides=(2, 2), pool_size=(3, 3))`\n",
      "/home/matt/Envs/keras/lib/python2.7/site-packages/ipykernel/__main__.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_initializer=\"he_normal\", padding=\"same\", strides=(1, 1), kernel_regularizer=<keras.reg..., filters=64, kernel_size=(3, 3))`\n",
      "/home/matt/Envs/keras/lib/python2.7/site-packages/ipykernel/__main__.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_initializer=\"he_normal\", padding=\"same\", strides=(1, 1), kernel_regularizer=<keras.reg..., filters=64, kernel_size=(3, 3))`\n",
      "/home/matt/Envs/keras/lib/python2.7/site-packages/ipykernel/__main__.py:22: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/home/matt/Envs/keras/local/lib/python2.7/site-packages/keras/legacy/layers.py:456: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n",
      "/home/matt/Envs/keras/lib/python2.7/site-packages/ipykernel/__main__.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_initializer=\"he_normal\", padding=\"same\", strides=(2, 2), kernel_regularizer=<keras.reg..., filters=128, kernel_size=(3, 3))`\n",
      "/home/matt/Envs/keras/lib/python2.7/site-packages/ipykernel/__main__.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_initializer=\"he_normal\", padding=\"same\", strides=(1, 1), kernel_regularizer=<keras.reg..., filters=128, kernel_size=(3, 3))`\n",
      "/home/matt/Envs/keras/lib/python2.7/site-packages/ipykernel/__main__.py:20: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_initializer=\"he_normal\", padding=\"valid\", strides=(2, 2), kernel_regularizer=<keras.reg..., filters=128, kernel_size=(1, 1))`\n",
      "/home/matt/Envs/keras/lib/python2.7/site-packages/ipykernel/__main__.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_initializer=\"he_normal\", padding=\"same\", strides=(2, 2), kernel_regularizer=<keras.reg..., filters=256, kernel_size=(3, 3))`\n",
      "/home/matt/Envs/keras/lib/python2.7/site-packages/ipykernel/__main__.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_initializer=\"he_normal\", padding=\"same\", strides=(1, 1), kernel_regularizer=<keras.reg..., filters=256, kernel_size=(3, 3))`\n",
      "/home/matt/Envs/keras/lib/python2.7/site-packages/ipykernel/__main__.py:20: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_initializer=\"he_normal\", padding=\"valid\", strides=(2, 2), kernel_regularizer=<keras.reg..., filters=256, kernel_size=(1, 1))`\n",
      "/home/matt/Envs/keras/lib/python2.7/site-packages/ipykernel/__main__.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_initializer=\"he_normal\", padding=\"same\", strides=(2, 2), kernel_regularizer=<keras.reg..., filters=512, kernel_size=(3, 3))`\n",
      "/home/matt/Envs/keras/lib/python2.7/site-packages/ipykernel/__main__.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_initializer=\"he_normal\", padding=\"same\", strides=(1, 1), kernel_regularizer=<keras.reg..., filters=512, kernel_size=(3, 3))`\n",
      "/home/matt/Envs/keras/lib/python2.7/site-packages/ipykernel/__main__.py:20: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_initializer=\"he_normal\", padding=\"valid\", strides=(2, 2), kernel_regularizer=<keras.reg..., filters=512, kernel_size=(1, 1))`\n",
      "/home/matt/Envs/keras/lib/python2.7/site-packages/ipykernel/__main__.py:41: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization(axis=3)`\n",
      "/home/matt/Envs/keras/lib/python2.7/site-packages/ipykernel/__main__.py:49: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=3, activation=\"softmax\", kernel_initializer=\"he_normal\")`\n",
      "/home/matt/Envs/keras/lib/python2.7/site-packages/ipykernel/__main__.py:52: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Softmax.0, inputs=/input_1)`\n"
     ]
    }
   ],
   "source": [
    "print('Create and compile model...')\n",
    "\n",
    "nb_classes = 3\n",
    "img_rows, img_cols = conf['image_shape'][1], conf['image_shape'][0]\n",
    "img_channels = 3\n",
    "\n",
    "model = ResnetBuilder.build_resnet_18((img_channels, img_rows, img_cols), nb_classes)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#model.compile(loss='hinge',optimizer='adadelta',metrics=['accuracy'])\n",
    "\n",
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1), cooldown=0, patience=conf['lr_patience'], min_lr=0.5e-6)\n",
    "early_stopper = EarlyStopping(min_delta=0.00001, patience=conf['stop_patience'])\n",
    "model_checkpoint = ModelCheckpoint('cervical_best.hdf5', monitor='val_loss', save_best_only=True, verbose=0)\n",
    "csv_logger = CSVLogger('resnet18_kcc3_18.csv')\n",
    "\n",
    "callbacks=[lr_reducer, early_stopper, model_checkpoint, csv_logger]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model...\n",
      "Using real-time data augmentation.\n",
      "Epoch 1/1000\n",
      "34s - loss: 2.0383 - acc: 0.4593 - val_loss: 14.4740 - val_acc: 0.1568\n",
      "Epoch 2/1000\n",
      "31s - loss: 1.8426 - acc: 0.5158 - val_loss: 14.4608 - val_acc: 0.1568\n",
      "Epoch 3/1000\n",
      "31s - loss: 1.7675 - acc: 0.5443 - val_loss: 14.4390 - val_acc: 0.1568\n",
      "Epoch 4/1000\n",
      "31s - loss: 1.7411 - acc: 0.5512 - val_loss: 14.4049 - val_acc: 0.1568\n",
      "Epoch 5/1000\n",
      "31s - loss: 1.6916 - acc: 0.5648 - val_loss: 11.8726 - val_acc: 0.1568\n",
      "Epoch 6/1000\n",
      "31s - loss: 1.6566 - acc: 0.5816 - val_loss: 10.4505 - val_acc: 0.2811\n",
      "Epoch 7/1000\n",
      "31s - loss: 1.6120 - acc: 0.5899 - val_loss: 4.6695 - val_acc: 0.2838\n",
      "Epoch 8/1000\n",
      "31s - loss: 1.6018 - acc: 0.5695 - val_loss: 2.2926 - val_acc: 0.3189\n",
      "Epoch 9/1000\n",
      "31s - loss: 1.5460 - acc: 0.6012 - val_loss: 1.7326 - val_acc: 0.4811\n",
      "Epoch 10/1000\n",
      "31s - loss: 1.5226 - acc: 0.5973 - val_loss: 3.1189 - val_acc: 0.2838\n",
      "Epoch 11/1000\n",
      "33s - loss: 1.5050 - acc: 0.5861 - val_loss: 1.9459 - val_acc: 0.3081\n",
      "Epoch 12/1000\n",
      "31s - loss: 1.4643 - acc: 0.6138 - val_loss: 2.0793 - val_acc: 0.3324\n",
      "Epoch 13/1000\n",
      "31s - loss: 1.4399 - acc: 0.6309 - val_loss: 2.7668 - val_acc: 0.2892\n",
      "Epoch 14/1000\n",
      "31s - loss: 1.4267 - acc: 0.5697 - val_loss: 1.8747 - val_acc: 0.3973\n",
      "Epoch 15/1000\n",
      "31s - loss: 1.3979 - acc: 0.6092 - val_loss: 1.7022 - val_acc: 0.5270\n",
      "Epoch 16/1000\n",
      "30s - loss: 1.3825 - acc: 0.5920 - val_loss: 1.7368 - val_acc: 0.4351\n",
      "Epoch 17/1000\n",
      "30s - loss: 1.3457 - acc: 0.6384 - val_loss: 4.3126 - val_acc: 0.2838\n",
      "Epoch 18/1000\n",
      "31s - loss: 1.3634 - acc: 0.5975 - val_loss: 1.4569 - val_acc: 0.5757\n",
      "Epoch 19/1000\n",
      "30s - loss: 1.3304 - acc: 0.6011 - val_loss: 1.7272 - val_acc: 0.5946\n",
      "Epoch 20/1000\n",
      "31s - loss: 1.2970 - acc: 0.6150 - val_loss: 1.9755 - val_acc: 0.4676\n",
      "Epoch 21/1000\n",
      "33s - loss: 1.3025 - acc: 0.6102 - val_loss: 2.1206 - val_acc: 0.3324\n",
      "Epoch 22/1000\n",
      "31s - loss: 1.2339 - acc: 0.6497 - val_loss: 1.4128 - val_acc: 0.5378\n",
      "Epoch 23/1000\n",
      "31s - loss: 1.2519 - acc: 0.6424 - val_loss: 1.7603 - val_acc: 0.4000\n",
      "Epoch 24/1000\n",
      "30s - loss: 1.2525 - acc: 0.6181 - val_loss: 1.4714 - val_acc: 0.5297\n",
      "Epoch 25/1000\n",
      "30s - loss: 1.2516 - acc: 0.6238 - val_loss: 1.4634 - val_acc: 0.5135\n",
      "Epoch 26/1000\n",
      "31s - loss: 1.2102 - acc: 0.6335 - val_loss: 2.3815 - val_acc: 0.2973\n",
      "Epoch 27/1000\n",
      "30s - loss: 1.2275 - acc: 0.5993 - val_loss: 1.5157 - val_acc: 0.5811\n",
      "Epoch 28/1000\n",
      "31s - loss: 1.1816 - acc: 0.6288 - val_loss: 1.3984 - val_acc: 0.5162\n",
      "Epoch 29/1000\n",
      "31s - loss: 1.1874 - acc: 0.6247 - val_loss: 1.3400 - val_acc: 0.5514\n",
      "Epoch 30/1000\n",
      "31s - loss: 1.1825 - acc: 0.6371 - val_loss: 1.2579 - val_acc: 0.5838\n",
      "Epoch 31/1000\n",
      "33s - loss: 1.1589 - acc: 0.6398 - val_loss: 1.5056 - val_acc: 0.4216\n",
      "Epoch 32/1000\n",
      "30s - loss: 1.1578 - acc: 0.6275 - val_loss: 1.3236 - val_acc: 0.5568\n",
      "Epoch 33/1000\n",
      "31s - loss: 1.1524 - acc: 0.6336 - val_loss: 1.7334 - val_acc: 0.2784\n",
      "Epoch 34/1000\n",
      "30s - loss: 1.1381 - acc: 0.6143 - val_loss: 1.3213 - val_acc: 0.5486\n",
      "Epoch 35/1000\n",
      "31s - loss: 1.1399 - acc: 0.6374 - val_loss: 1.5016 - val_acc: 0.4351\n",
      "Epoch 36/1000\n",
      "30s - loss: 1.1097 - acc: 0.6426 - val_loss: 1.9792 - val_acc: 0.3676\n",
      "Epoch 37/1000\n",
      "30s - loss: 1.1206 - acc: 0.6341 - val_loss: 1.6747 - val_acc: 0.3622\n",
      "Epoch 38/1000\n",
      "31s - loss: 1.1232 - acc: 0.6287 - val_loss: 1.2457 - val_acc: 0.5703\n",
      "Epoch 39/1000\n",
      "31s - loss: 1.0740 - acc: 0.6550 - val_loss: 1.2078 - val_acc: 0.5486\n",
      "Epoch 40/1000\n",
      "31s - loss: 1.1150 - acc: 0.6354 - val_loss: 1.6631 - val_acc: 0.2865\n",
      "Epoch 41/1000\n",
      "33s - loss: 1.0721 - acc: 0.6574 - val_loss: 1.1547 - val_acc: 0.5649\n",
      "Epoch 42/1000\n",
      "31s - loss: 1.0535 - acc: 0.6482 - val_loss: 1.2537 - val_acc: 0.5162\n",
      "Epoch 43/1000\n",
      "31s - loss: 1.1076 - acc: 0.6199 - val_loss: 1.2216 - val_acc: 0.5135\n",
      "Epoch 44/1000\n",
      "31s - loss: 1.0918 - acc: 0.6340 - val_loss: 1.1357 - val_acc: 0.5730\n",
      "Epoch 45/1000\n",
      "31s - loss: 1.0364 - acc: 0.6511 - val_loss: 1.1959 - val_acc: 0.5757\n",
      "Epoch 46/1000\n",
      "31s - loss: 1.0817 - acc: 0.6238 - val_loss: 1.0989 - val_acc: 0.5541\n",
      "Epoch 47/1000\n",
      "30s - loss: 1.0552 - acc: 0.6302 - val_loss: 1.5438 - val_acc: 0.4946\n",
      "Epoch 48/1000\n",
      "30s - loss: 1.0649 - acc: 0.6179 - val_loss: 1.1657 - val_acc: 0.5541\n",
      "Epoch 49/1000\n",
      "30s - loss: 1.0563 - acc: 0.6511 - val_loss: 1.2334 - val_acc: 0.5595\n",
      "Epoch 50/1000\n",
      "31s - loss: 1.0740 - acc: 0.6115 - val_loss: 1.1355 - val_acc: 0.6054\n",
      "Epoch 51/1000\n",
      "33s - loss: 1.0471 - acc: 0.6296 - val_loss: 1.0573 - val_acc: 0.6054\n",
      "Epoch 52/1000\n",
      "30s - loss: 1.0263 - acc: 0.6415 - val_loss: 1.1542 - val_acc: 0.5676\n",
      "Epoch 53/1000\n",
      "30s - loss: 1.0361 - acc: 0.6514 - val_loss: 1.2410 - val_acc: 0.4811\n",
      "Epoch 54/1000\n",
      "31s - loss: 0.9959 - acc: 0.6487 - val_loss: 1.1878 - val_acc: 0.5135\n",
      "Epoch 55/1000\n",
      "30s - loss: 1.0327 - acc: 0.6350 - val_loss: 1.0888 - val_acc: 0.5892\n",
      "Epoch 56/1000\n",
      "30s - loss: 1.0163 - acc: 0.6522 - val_loss: 1.1872 - val_acc: 0.5162\n",
      "Epoch 57/1000\n",
      "30s - loss: 1.0011 - acc: 0.6463 - val_loss: 1.2216 - val_acc: 0.5757\n",
      "Epoch 58/1000\n",
      "30s - loss: 1.0182 - acc: 0.6372 - val_loss: 1.9780 - val_acc: 0.3514\n",
      "Epoch 59/1000\n",
      "30s - loss: 1.0196 - acc: 0.6382 - val_loss: 1.1647 - val_acc: 0.5784\n",
      "Epoch 60/1000\n",
      "31s - loss: 0.9896 - acc: 0.6871 - val_loss: 1.4591 - val_acc: 0.5270\n",
      "Epoch 61/1000\n",
      "33s - loss: 1.0021 - acc: 0.6444 - val_loss: 1.1357 - val_acc: 0.5622\n",
      "Epoch 62/1000\n",
      "30s - loss: 0.9656 - acc: 0.6500 - val_loss: 1.1111 - val_acc: 0.5595\n",
      "Epoch 63/1000\n",
      "30s - loss: 0.9857 - acc: 0.6538 - val_loss: 1.3196 - val_acc: 0.4432\n",
      "Epoch 64/1000\n",
      "30s - loss: 0.9829 - acc: 0.6655 - val_loss: 1.0686 - val_acc: 0.6027\n",
      "Epoch 65/1000\n",
      "30s - loss: 0.9626 - acc: 0.6748 - val_loss: 1.1487 - val_acc: 0.5432\n",
      "Epoch 66/1000\n",
      "30s - loss: 0.9681 - acc: 0.6635 - val_loss: 1.2082 - val_acc: 0.5676\n",
      "Epoch 67/1000\n",
      "30s - loss: 0.9631 - acc: 0.6424 - val_loss: 1.2447 - val_acc: 0.5189\n",
      "Epoch 68/1000\n",
      "31s - loss: 0.9827 - acc: 0.6326 - val_loss: 1.0536 - val_acc: 0.5703\n",
      "Epoch 69/1000\n",
      "30s - loss: 0.9871 - acc: 0.6410 - val_loss: 1.1176 - val_acc: 0.5595\n",
      "Epoch 70/1000\n",
      "31s - loss: 0.9377 - acc: 0.6679 - val_loss: 1.1506 - val_acc: 0.5297\n",
      "Epoch 71/1000\n",
      "33s - loss: 0.9622 - acc: 0.6565 - val_loss: 1.2150 - val_acc: 0.4946\n",
      "Epoch 72/1000\n",
      "30s - loss: 0.9654 - acc: 0.6403 - val_loss: 1.1736 - val_acc: 0.5514\n",
      "Epoch 73/1000\n",
      "30s - loss: 0.9733 - acc: 0.6526 - val_loss: 1.1544 - val_acc: 0.5622\n",
      "Epoch 74/1000\n",
      "30s - loss: 0.9487 - acc: 0.6573 - val_loss: 1.0561 - val_acc: 0.5865\n",
      "Epoch 75/1000\n",
      "30s - loss: 0.9463 - acc: 0.6629 - val_loss: 1.4484 - val_acc: 0.4649\n",
      "Epoch 76/1000\n",
      "31s - loss: 0.9331 - acc: 0.6486 - val_loss: 1.0500 - val_acc: 0.6108\n",
      "Epoch 77/1000\n",
      "30s - loss: 0.9782 - acc: 0.6440 - val_loss: 1.1391 - val_acc: 0.5324\n",
      "Epoch 78/1000\n",
      "31s - loss: 0.9380 - acc: 0.6610 - val_loss: 1.0279 - val_acc: 0.5919\n",
      "Epoch 79/1000\n",
      "31s - loss: 0.9435 - acc: 0.6522 - val_loss: 1.7395 - val_acc: 0.3135\n",
      "Epoch 80/1000\n",
      "31s - loss: 0.9493 - acc: 0.6319 - val_loss: 1.0082 - val_acc: 0.6108\n",
      "Epoch 81/1000\n",
      "33s - loss: 0.9167 - acc: 0.6657 - val_loss: 1.2283 - val_acc: 0.4568\n",
      "Epoch 82/1000\n",
      "30s - loss: 0.9334 - acc: 0.6493 - val_loss: 1.1691 - val_acc: 0.5108\n",
      "Epoch 83/1000\n",
      "31s - loss: 0.9401 - acc: 0.6546 - val_loss: 1.1552 - val_acc: 0.5405\n",
      "Epoch 84/1000\n",
      "31s - loss: 0.9142 - acc: 0.6594 - val_loss: 1.2752 - val_acc: 0.4676\n",
      "Epoch 85/1000\n",
      "30s - loss: 0.9215 - acc: 0.6667 - val_loss: 1.1610 - val_acc: 0.5405\n",
      "Epoch 86/1000\n",
      "30s - loss: 0.9393 - acc: 0.6443 - val_loss: 1.0688 - val_acc: 0.5946\n",
      "Epoch 87/1000\n",
      "31s - loss: 0.8813 - acc: 0.6994 - val_loss: 0.9972 - val_acc: 0.6162\n",
      "Epoch 88/1000\n",
      "31s - loss: 0.8704 - acc: 0.7007 - val_loss: 1.2270 - val_acc: 0.5216\n",
      "Epoch 89/1000\n",
      "31s - loss: 0.9136 - acc: 0.6738 - val_loss: 1.2938 - val_acc: 0.4946\n",
      "Epoch 90/1000\n",
      "31s - loss: 0.8954 - acc: 0.6671 - val_loss: 1.4414 - val_acc: 0.4649\n",
      "Epoch 91/1000\n",
      "33s - loss: 0.9053 - acc: 0.6796 - val_loss: 1.6857 - val_acc: 0.4162\n",
      "Epoch 92/1000\n",
      "30s - loss: 0.9053 - acc: 0.6758 - val_loss: 1.0297 - val_acc: 0.5703\n",
      "Epoch 93/1000\n",
      "31s - loss: 0.9003 - acc: 0.6794 - val_loss: 1.0289 - val_acc: 0.5784\n",
      "Epoch 94/1000\n",
      "30s - loss: 0.8675 - acc: 0.6871 - val_loss: 1.1917 - val_acc: 0.5459\n",
      "Epoch 95/1000\n",
      "30s - loss: 0.8989 - acc: 0.6781 - val_loss: 1.0511 - val_acc: 0.5865\n",
      "Epoch 96/1000\n",
      "30s - loss: 0.8872 - acc: 0.6788 - val_loss: 1.0270 - val_acc: 0.6108\n",
      "Epoch 97/1000\n",
      "30s - loss: 0.8769 - acc: 0.6974 - val_loss: 1.2042 - val_acc: 0.5514\n",
      "Epoch 98/1000\n",
      "30s - loss: 0.9052 - acc: 0.6772 - val_loss: 1.3698 - val_acc: 0.5027\n",
      "Epoch 99/1000\n",
      "30s - loss: 0.9025 - acc: 0.6606 - val_loss: 1.1262 - val_acc: 0.5486\n",
      "Epoch 100/1000\n",
      "31s - loss: 0.9344 - acc: 0.6353 - val_loss: 1.0983 - val_acc: 0.5649\n",
      "Epoch 101/1000\n",
      "33s - loss: 0.8932 - acc: 0.6713 - val_loss: 1.2865 - val_acc: 0.4189\n",
      "Epoch 102/1000\n",
      "30s - loss: 0.9263 - acc: 0.6354 - val_loss: 1.1561 - val_acc: 0.5351\n",
      "Epoch 103/1000\n",
      "30s - loss: 0.8635 - acc: 0.6841 - val_loss: 1.0584 - val_acc: 0.5946\n",
      "Epoch 104/1000\n",
      "30s - loss: 0.8934 - acc: 0.6646 - val_loss: 1.0369 - val_acc: 0.5811\n",
      "Epoch 105/1000\n",
      "30s - loss: 0.8805 - acc: 0.6693 - val_loss: 1.0922 - val_acc: 0.5649\n",
      "Epoch 106/1000\n",
      "30s - loss: 0.8796 - acc: 0.6858 - val_loss: 1.5608 - val_acc: 0.5000\n",
      "Epoch 107/1000\n",
      "30s - loss: 0.9067 - acc: 0.6758 - val_loss: 1.2321 - val_acc: 0.5432\n",
      "Epoch 108/1000\n",
      "31s - loss: 0.8946 - acc: 0.6653 - val_loss: 1.4838 - val_acc: 0.4649\n",
      "Epoch 109/1000\n",
      "30s - loss: 0.8908 - acc: 0.6830 - val_loss: 1.0873 - val_acc: 0.5541\n",
      "Epoch 110/1000\n",
      "31s - loss: 0.8763 - acc: 0.6804 - val_loss: 1.2122 - val_acc: 0.4514\n",
      "Epoch 111/1000\n",
      "33s - loss: 0.8647 - acc: 0.6750 - val_loss: 1.5968 - val_acc: 0.3757\n",
      "Epoch 112/1000\n",
      "30s - loss: 0.8244 - acc: 0.6998 - val_loss: 2.4863 - val_acc: 0.3405\n",
      "Epoch 113/1000\n",
      "30s - loss: 0.8646 - acc: 0.6886 - val_loss: 1.3635 - val_acc: 0.4703\n",
      "Epoch 114/1000\n",
      "30s - loss: 0.8582 - acc: 0.7062 - val_loss: 1.3259 - val_acc: 0.4541\n",
      "Epoch 115/1000\n",
      "30s - loss: 0.9205 - acc: 0.6427 - val_loss: 1.5756 - val_acc: 0.4000\n",
      "Epoch 116/1000\n",
      "31s - loss: 0.9162 - acc: 0.6765 - val_loss: 1.1354 - val_acc: 0.5892\n",
      "Epoch 117/1000\n",
      "30s - loss: 0.8912 - acc: 0.6711 - val_loss: 2.2834 - val_acc: 0.2595\n",
      "Epoch 118/1000\n",
      "31s - loss: 0.8395 - acc: 0.7095 - val_loss: 1.6787 - val_acc: 0.3946\n",
      "Epoch 119/1000\n",
      "31s - loss: 0.8360 - acc: 0.7005 - val_loss: 1.8111 - val_acc: 0.3270\n",
      "Epoch 120/1000\n",
      "31s - loss: 0.8889 - acc: 0.6786 - val_loss: 1.1129 - val_acc: 0.5162\n",
      "Epoch 121/1000\n",
      "33s - loss: 0.9027 - acc: 0.6787 - val_loss: 1.1518 - val_acc: 0.5541\n",
      "Epoch 122/1000\n",
      "30s - loss: 0.8403 - acc: 0.6946 - val_loss: 1.0746 - val_acc: 0.5811\n",
      "Epoch 123/1000\n",
      "30s - loss: 0.8813 - acc: 0.6854 - val_loss: 1.0899 - val_acc: 0.5973\n",
      "Epoch 124/1000\n",
      "30s - loss: 0.8469 - acc: 0.6882 - val_loss: 1.0534 - val_acc: 0.5757\n",
      "Epoch 125/1000\n",
      "30s - loss: 0.8529 - acc: 0.6827 - val_loss: 1.4226 - val_acc: 0.5838\n",
      "Epoch 126/1000\n",
      "30s - loss: 0.8233 - acc: 0.7108 - val_loss: 2.3864 - val_acc: 0.2973\n",
      "Epoch 127/1000\n",
      "30s - loss: 0.8661 - acc: 0.6896 - val_loss: 1.0886 - val_acc: 0.5946\n",
      "Epoch 128/1000\n",
      "30s - loss: 0.8542 - acc: 0.7015 - val_loss: 1.5805 - val_acc: 0.4405\n",
      "Epoch 129/1000\n",
      "30s - loss: 0.8573 - acc: 0.6950 - val_loss: 1.3495 - val_acc: 0.5838\n",
      "Epoch 130/1000\n",
      "31s - loss: 0.8316 - acc: 0.6925 - val_loss: 1.1426 - val_acc: 0.5081\n",
      "Epoch 131/1000\n",
      "33s - loss: 0.7983 - acc: 0.7167 - val_loss: 0.9983 - val_acc: 0.6189\n",
      "Epoch 132/1000\n",
      "30s - loss: 0.7899 - acc: 0.7189 - val_loss: 1.1538 - val_acc: 0.5243\n",
      "Epoch 133/1000\n",
      "30s - loss: 0.8249 - acc: 0.7033 - val_loss: 1.4167 - val_acc: 0.3405\n",
      "Epoch 134/1000\n",
      "30s - loss: 0.8238 - acc: 0.6863 - val_loss: 1.0485 - val_acc: 0.5568\n",
      "Epoch 135/1000\n",
      "30s - loss: 0.8189 - acc: 0.7118 - val_loss: 1.0555 - val_acc: 0.5865\n",
      "Epoch 136/1000\n",
      "31s - loss: 0.8332 - acc: 0.7006 - val_loss: 1.1391 - val_acc: 0.5135\n",
      "Epoch 137/1000\n",
      "31s - loss: 0.8196 - acc: 0.6964 - val_loss: 1.2736 - val_acc: 0.5459\n",
      "Epoch 138/1000\n"
     ]
    }
   ],
   "source": [
    "print(\"Fitting model...\")\n",
    "if not conf['data_augmentation']:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(X_train, Y_train,\n",
    "              batch_size=batch_size,\n",
    "              nb_epoch=nb_epoch,\n",
    "              validation_data=(X_test, Y_test),\n",
    "              shuffle=True,\n",
    "              verbose=2,\n",
    "              callbacks=callbacks)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=180,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.15,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.15,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "    \n",
    "    # Compute quantities required for featurewise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(X_train)\n",
    "    \n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    model.fit_generator(datagen.flow(X_train, Y_train, batch_size=conf['batch_size']),\n",
    "                        steps_per_epoch=X_train.shape[0] // conf['batch_size'],\n",
    "                        validation_data=(X_valid, Y_valid),\n",
    "                        epochs=conf['nb_epoch'], verbose=2, max_q_size=100,\n",
    "                        callbacks=callbacks)\n",
    "\n",
    "model.save(\"../models/resnet18_subm18.h5\")\n",
    "\n",
    "print(\"...Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Create submission files with prediction for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n",
      "... Done\n"
     ]
    }
   ],
   "source": [
    "sample_subm = pd.read_csv(\"../data/sample_submission.csv\")\n",
    "ids = sample_subm['image_name'].values\n",
    "\n",
    "print(\"Making predictions...\")\n",
    "for id in ids:\n",
    "#    print('Predict for image {}'.format(id))\n",
    "    files = glob.glob( join(gFilesBase, \"test/unknown/\" + id) )\n",
    "    image_list = []\n",
    "    for f in files:\n",
    "        image = cv2.imread(f)\n",
    "        image = cv2.resize(image, conf['image_shape'])\n",
    "        image_list.append(image)\n",
    "        \n",
    "    image_list = np.array(image_list)\n",
    "\n",
    "    predictions = model.predict(image_list, verbose=0, batch_size=1)\n",
    "\n",
    "    sample_subm.loc[sample_subm['image_name'] == id, 'Type_1'] = predictions[0,0]\n",
    "    sample_subm.loc[sample_subm['image_name'] == id, 'Type_2'] = predictions[0,1]\n",
    "    sample_subm.loc[sample_subm['image_name'] == id, 'Type_3'] = predictions[0,2]\n",
    "    \n",
    "sample_subm.to_csv(\"../submissions/subm17.csv\", index=False)\n",
    "\n",
    "print(\"... Done\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Model Notes:\n",
    "\n",
    "#5. \n",
    "192x192, early stopping after ~100 epochs.  First model to include (segmented) additional training data\n",
    "loss: 0.8371 - acc: 0.6851 - val_loss: 1.0162 - val_acc: 0.6023\n",
    "\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=180,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=True)  # randomly flip images\n",
    "\n",
    "\n",
    "#6. \n",
    "58s - loss: 0.8437 - acc: 0.6743 - val_loss: 9.5252 - val_acc: 0.4074\n",
    "Epoch 75/200\n",
    "\n",
    "Validation loss would not budge, killed it.\n",
    "\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=True,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=180,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=True)  # randomly flip images\n",
    "\n",
    "\n",
    "#7. \n",
    "Epoch 65/200\n",
    "33s - loss: 1.0168 - acc: 0.6604 - val_loss: 1.0923 - val_acc: 0.6297\n",
    "Stopped on its own.  Only used original training set.\n",
    "\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=True,  # apply ZCA whitening\n",
    "        rotation_range=180,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "\n",
    "#8. \n",
    "Epoch 68/200\n",
    "57s - loss: 0.8332 - acc: 0.6768 - val_loss: 0.9782 - val_acc: 0.5862\n",
    "Using augmented training set, otherwise same as #7\n",
    "\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=True,  # apply ZCA whitening\n",
    "        rotation_range=180,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "\n",
    "#9. \n",
    "Epoch 47/200\n",
    "33s - loss: 0.9996 - acc: 0.6944 - val_loss: 1.4574 - val_acc: 0.4622\n",
    "Stopped on its own.  Only used original training set.\n",
    "\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=True,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=True,  # apply ZCA whitening\n",
    "        rotation_range=180,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "\n",
    "#10. \n",
    "58s - loss: 0.9724 - acc: 0.7001 - val_loss: 1.1917 - val_acc: 0.5351\n",
    "Epoch 55/200\n",
    "58s - loss: 0.9849 - acc: 0.6817 - val_loss: 1.1903 - val_acc: 0.5568\n",
    "Epoch 56/200\n",
    "58s - loss: 1.0009 - acc: 0.6741 - val_loss: 1.2002 - val_acc: 0.5270\n",
    "Epoch 57/200\n",
    "58s - loss: 1.0055 - acc: 0.6826 - val_loss: 1.2418 - val_acc: 0.5243\n",
    "ResNet_50, otherwise mostly the same as #7\n",
    "\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=True,  # apply ZCA whitening\n",
    "        rotation_range=180,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.15,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.15,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "\n",
    "#11. \n",
    "98s - loss: 0.9434 - acc: 0.6249 - val_loss: 0.9867 - val_acc: 0.5919\n",
    "Epoch 56/200\n",
    "98s - loss: 0.9211 - acc: 0.6454 - val_loss: 1.0735 - val_acc: 0.5189\n",
    "Epoch 57/200\n",
    "98s - loss: 0.9314 - acc: 0.6388 - val_loss: 1.1562 - val_acc: 0.4973\n",
    "Epoch 58/200\n",
    "98s - loss: 0.9161 - acc: 0.6467 - val_loss: 1.3069 - val_acc: 0.4514\n",
    "ResNet_101, otherwise mostly the same as #7\n",
    "\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=True,  # apply ZCA whitening\n",
    "        rotation_range=180,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.15,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.15,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "\n",
    "#12. \n",
    "33s - loss: 1.0990 - acc: 0.6254 - val_loss: 1.3437 - val_acc: 0.3541\n",
    "Epoch 44/200\n",
    "33s - loss: 1.0470 - acc: 0.6574 - val_loss: 1.3389 - val_acc: 0.3243\n",
    "Epoch 45/200\n",
    "33s - loss: 1.0864 - acc: 0.6262 - val_loss: 1.3281 - val_acc: 0.3730\n",
    "Epoch 46/200\n",
    "33s - loss: 1.0384 - acc: 0.6581 - val_loss: 1.2831 - val_acc: 0.4135\n",
    "ResNet_34, otherwise identical to 10, 11\n",
    "\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=True,  # apply ZCA whitening\n",
    "        rotation_range=180,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.15,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.15,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "lr_schedule = [0.5, 0.75]\n",
    "\n",
    "def residual_drop(x, input_shape, output_shape, strides=(1, 1)):\n",
    "    global add_tables\n",
    "\n",
    "    nb_filter = output_shape[0]\n",
    "    conv = Convolution2D(nb_filter, 3, 3, subsample=strides,\n",
    "                         border_mode=\"same\", W_regularizer=l2(weight_decay))(x)\n",
    "    conv = BatchNormalization(axis=1)(conv)\n",
    "    conv = Activation(\"relu\")(conv)\n",
    "    conv = Convolution2D(nb_filter, 3, 3,\n",
    "                         border_mode=\"same\", W_regularizer=l2(weight_decay))(conv)\n",
    "    conv = BatchNormalization(axis=1)(conv)\n",
    "\n",
    "    if strides[0] >= 2:\n",
    "        x = AveragePooling2D(strides)(x)\n",
    "\n",
    "    if (output_shape[0] - input_shape[0]) > 0:\n",
    "        pad_shape = (1,\n",
    "                     output_shape[0] - input_shape[0],\n",
    "                     output_shape[1],\n",
    "                     output_shape[2])\n",
    "        padding = K.zeros(pad_shape)\n",
    "        padding = K.repeat_elements(padding, K.shape(x)[0], axis=0)\n",
    "        x = Lambda(lambda y: K.concatenate([y, padding], axis=1),\n",
    "                   output_shape=output_shape)(x)\n",
    "\n",
    "    _death_rate = K.variable(death_rate)\n",
    "    scale = K.ones_like(conv) - _death_rate\n",
    "    conv = Lambda(lambda c: K.in_test_phase(scale * c, c),\n",
    "                  output_shape=output_shape)(conv)\n",
    "\n",
    "    out = merge([conv, x], mode=\"sum\")\n",
    "    out = Activation(\"relu\")(out)\n",
    "\n",
    "    gate = K.variable(1, dtype=\"uint8\")\n",
    "    add_tables += [{\"death_rate\": _death_rate, \"gate\": gate}]\n",
    "    return Lambda(lambda tensors: K.switch(gate, tensors[0], tensors[1]),\n",
    "                  output_shape=output_shape)([out, x])\n",
    "\n",
    "\n",
    "def open_all_gates():\n",
    "    for t in add_tables:\n",
    "        K.set_value(t[\"gate\"], 1)\n",
    "\n",
    "\n",
    "class GatesUpdate(Callback):\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        open_all_gates()\n",
    "\n",
    "        rands = np.random.uniform(size=len(add_tables))\n",
    "        for t, rand in zip(add_tables, rands):\n",
    "            if rand < K.get_value(t[\"death_rate\"]):\n",
    "                K.set_value(t[\"gate\"], 0)\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        open_all_gates()  # for validation\n",
    "\n",
    "\n",
    "def schedule(epoch_idx):\n",
    "    if (epoch_idx + 1) < (conf['nb_epoch'] * lr_schedule[0]):\n",
    "        return 0.1\n",
    "    elif (epoch_idx + 1) < (conf['nb_epoch'] * lr_schedule[1]):\n",
    "        return 0.01\n",
    "\n",
    "    return 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#N = 18\n",
    "#weight_decay = 1e-4\n",
    "\n",
    "death_mode = \"lin_decay\"  # or uniform\n",
    "death_rate = 0.5\n",
    "\n",
    "add_tables = []\n",
    "\n",
    "inputs = Input(shape=(img_channels, img_rows, img_cols))\n",
    "\n",
    "net = Convolution2D(16, 3, 3, border_mode=\"same\", W_regularizer=l2(weight_decay))(inputs)\n",
    "net = BatchNormalization(axis=1)(net)\n",
    "net = Activation(\"relu\")(net)\n",
    "\n",
    "\n",
    "\n",
    "for i in range(N):\n",
    "    net = residual_drop(net, input_shape=(16, 32, 32), output_shape=(16, 32, 32))\n",
    "\n",
    "net = residual_drop(\n",
    "    net,\n",
    "    input_shape=(16, 32, 32),\n",
    "    output_shape=(32, 16, 16),\n",
    "    strides=(2, 2)\n",
    ")\n",
    "for i in range(N - 1):\n",
    "    net = residual_drop(\n",
    "        net,\n",
    "        input_shape=(32, 16, 16),\n",
    "        output_shape=(32, 16, 16)\n",
    "    )\n",
    "\n",
    "net = residual_drop(\n",
    "    net,\n",
    "    input_shape=(32, 16, 16),\n",
    "    output_shape=(64, 8, 8),\n",
    "    strides=(2, 2)\n",
    ")\n",
    "for i in range(N - 1):\n",
    "    net = residual_drop(\n",
    "        net,\n",
    "        input_shape=(64, 8, 8),\n",
    "        output_shape=(64, 8, 8)\n",
    "    )\n",
    "\n",
    "pool = AveragePooling2D((8, 8))(net)\n",
    "flatten = Flatten()(pool)\n",
    "\n",
    "predictions = Dense(10, activation=\"softmax\", W_regularizer=l2(weight_decay))(flatten)\n",
    "model = Model(input=inputs, output=predictions)\n",
    "\n",
    "sgd = SGD(lr=0.1, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer=sgd, loss=\"categorical_crossentropy\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=True,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=False,\n",
    "    rotation_range=0,\n",
    "    width_shift_range=0.,\n",
    "    height_shift_range=0.,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False)\n",
    "datagen.fit(X_train)\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=True,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=False,\n",
    "    rotation_range=0,\n",
    "    width_shift_range=0.,\n",
    "    height_shift_range=0.,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False)\n",
    "test_datagen.fit(X_test)\n",
    "\n",
    "# fit the model on the batches generated by datagen.flow()\n",
    "model.fit_generator(datagen.flow(X_train, Y_train, batch_size=batch_size, shuffle=True),\n",
    "                    samples_per_epoch=X_train.shape[0],\n",
    "                    nb_epoch=nb_epoch,\n",
    "                    validation_data=test_datagen.flow(X_test, Y_test, batch_size=batch_size),\n",
    "                    nb_val_samples=X_test.shape[0],\n",
    "                    callbacks=[GatesUpdate(), LearningRateScheduler(schedule)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# setup death rate\\nfor i, tb in enumerate(add_tables, start=1):\\n    if death_mode == \"uniform\":\\n        K.set_value(tb[\"death_rate\"], death_rate)\\n    elif death_mode == \"lin_decay\":\\n        K.set_value(tb[\"death_rate\"], i / len(add_tables) * death_rate)\\n    else:\\n        raise\\n'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1), cooldown=0, patience=conf['lr_patience'], min_lr=0.5e-6)\n",
    "early_stopper = EarlyStopping(min_delta=0.00001, patience=conf['stop_patience'])\n",
    "csv_logger = CSVLogger('resnet34_kcc3_15.csv')\n",
    "\n",
    "\"\"\"\n",
    "# setup death rate\n",
    "for i, tb in enumerate(add_tables, start=1):\n",
    "    if death_mode == \"uniform\":\n",
    "        K.set_value(tb[\"death_rate\"], death_rate)\n",
    "    elif death_mode == \"lin_decay\":\n",
    "        K.set_value(tb[\"death_rate\"], i / len(add_tables) * death_rate)\n",
    "    else:\n",
    "        raise\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model...\n",
      "Using real-time data augmentation.\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "global name 'add_tables' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-09f4b17f643c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m                         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nb_epoch'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_q_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m                         callbacks=[lr_reducer, early_stopper, csv_logger, GatesUpdate(), LearningRateScheduler(schedule)])\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../models/resnet34_subm15.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/matt/Envs/keras/local/lib/python2.7/site-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     87\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_support_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/matt/Envs/keras/local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_q_size, workers, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1870\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'batch'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1871\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1872\u001b[0;31m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1874\u001b[0m                     outs = self.train_on_batch(x, y,\n",
      "\u001b[0;32m/home/matt/Envs/keras/local/lib/python2.7/site-packages/keras/callbacks.pyc\u001b[0m in \u001b[0;36mon_batch_begin\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mt_before_callbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts_batch_begin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt_before_callbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mdelta_t_median\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts_batch_begin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-59-91fe909a44d4>\u001b[0m in \u001b[0;36mon_batch_begin\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mGatesUpdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mopen_all_gates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mrands\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madd_tables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-59-91fe909a44d4>\u001b[0m in \u001b[0;36mopen_all_gates\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mopen_all_gates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0madd_tables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"gate\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'add_tables' is not defined"
     ]
    }
   ],
   "source": [
    "conf['nb_epoch'] = 200\n",
    "conf['data_augmentation'] = True\n",
    "\n",
    "print(\"Fitting model...\")\n",
    "if not conf['data_augmentation']:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(X_train, Y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=conf['nb_epoch'],\n",
    "              validation_data=(X_test, Y_test),\n",
    "              shuffle=True,\n",
    "              verbose=2,\n",
    "              callbacks=[lr_reducer, early_stopper, csv_logger])\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=180,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.15,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.15,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "    \n",
    "    # Compute quantities required for featurewise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(X_train)\n",
    "    \n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    model.fit_generator(datagen.flow(X_train, Y_train, batch_size=conf['batch_size']),\n",
    "                        steps_per_epoch=X_train.shape[0] // conf['batch_size'],\n",
    "                        validation_data=(X_valid, Y_valid),\n",
    "                        epochs=conf['nb_epoch'], verbose=2, max_q_size=100,\n",
    "                        callbacks=[lr_reducer, early_stopper, csv_logger, GatesUpdate(), LearningRateScheduler(schedule)])\n",
    "\n",
    "model.save(\"../models/resnet34_subm15.h5\")\n",
    "print(\"...Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Callback' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-9fda56cf05e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mGatesUpdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mopen_all_gates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Callback' is not defined"
     ]
    }
   ],
   "source": [
    "tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
