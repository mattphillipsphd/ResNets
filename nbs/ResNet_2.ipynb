{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Copied and modified from Rodney Thomas' posted version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import six\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import glob\n",
    "import random\n",
    "\n",
    "from os.path import join\n",
    "\n",
    "np.random.seed(2016)\n",
    "random.seed(2016)\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Activation, merge, Dense, Flatten, Lambda\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ReduceLROnPlateau, CSVLogger, EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Removes autoscroll throughout process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
       "    return false;\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Global Declarations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "conf = dict()\n",
    "\n",
    "# How many patients will be in train and validation set during training. Range: (0; 1)\n",
    "conf['train_valid_fraction'] = 0.75\n",
    "\n",
    "# Batch size for CNN [Depends on GPU and memory available]\n",
    "conf['batch_size'] = 15\n",
    "\n",
    "# Number of epochs for CNN training\n",
    "#conf['nb_epoch'] = 200\n",
    "conf['nb_epoch'] = 10\n",
    "\n",
    "# Early stopping. Stop training after epochs without improving on validation\n",
    "conf['patience'] = 3\n",
    "\n",
    "# Shape of image for CNN (Larger the better, but you need to increase CNN as well)\n",
    "#conf['image_shape'] = (4160,4128)\n",
    "#conf['image_shape'] = (2080,2064)\n",
    "#conf['image_shape'] = (1024,1024)\n",
    "conf['image_shape'] = (192,192)\n",
    "\n",
    "conf['data_augmentation'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Residual Network Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def _bn_relu(input):\n",
    "    \"\"\"Helper to build a BN -> relu block\n",
    "    \"\"\"\n",
    "    norm = BatchNormalization(axis=CHANNEL_AXIS)(input)\n",
    "    return Activation(\"relu\")(norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def _conv_bn_relu(**conv_params):\n",
    "    \"\"\"Helper to build a conv -> BN -> relu block\n",
    "    \"\"\"\n",
    "    nb_filter = conv_params[\"nb_filter\"]\n",
    "    nb_row = conv_params[\"nb_row\"]\n",
    "    nb_col = conv_params[\"nb_col\"]\n",
    "    subsample = conv_params.setdefault(\"subsample\", (1, 1))\n",
    "    init = conv_params.setdefault(\"init\", \"he_normal\")\n",
    "    border_mode = conv_params.setdefault(\"border_mode\", \"same\")\n",
    "    W_regularizer = conv_params.setdefault(\"W_regularizer\", l2(1.e-4))\n",
    "\n",
    "    def f(input):\n",
    "        conv = Convolution2D(nb_filter=nb_filter, nb_row=nb_row, nb_col=nb_col, subsample=subsample,\n",
    "                             init=init, border_mode=border_mode, W_regularizer=W_regularizer)(input)\n",
    "        return _bn_relu(conv)\n",
    "\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def _bn_relu_conv(**conv_params):\n",
    "    \"\"\"Helper to build a BN -> relu -> conv block.\n",
    "    This is an improved scheme proposed in http://arxiv.org/pdf/1603.05027v2.pdf\n",
    "    \"\"\"\n",
    "    nb_filter = conv_params[\"nb_filter\"]\n",
    "    nb_row = conv_params[\"nb_row\"]\n",
    "    nb_col = conv_params[\"nb_col\"]\n",
    "    subsample = conv_params.setdefault(\"subsample\", (1,1))\n",
    "    init = conv_params.setdefault(\"init\", \"he_normal\")\n",
    "    border_mode = conv_params.setdefault(\"border_mode\", \"same\")\n",
    "    W_regularizer = conv_params.setdefault(\"W_regularizer\", l2(1.e-4))\n",
    "\n",
    "    def f(input):\n",
    "        activation = _bn_relu(input)\n",
    "        return Convolution2D(nb_filter=nb_filter, nb_row=nb_row, nb_col=nb_col, subsample=subsample,\n",
    "                             init=init, border_mode=border_mode, W_regularizer=W_regularizer)(activation)\n",
    "\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def _shortcut(input, residual):\n",
    "    \"\"\"Adds a shortcut between input and residual block and merges them with \"sum\"\n",
    "    \"\"\"\n",
    "    # Expand channels of shortcut to match residual.\n",
    "    # Stride appropriately to match residual (width, height)\n",
    "    # Should be int if network architecture is correctly configured.\n",
    "    input_shape = K.int_shape(input)\n",
    "    residual_shape = K.int_shape(residual)\n",
    "    stride_width = int(round(input_shape[ROW_AXIS] / residual_shape[ROW_AXIS]))\n",
    "    stride_height = int(round(input_shape[COL_AXIS] / residual_shape[COL_AXIS]))\n",
    "    equal_channels = input_shape[CHANNEL_AXIS] == residual_shape[CHANNEL_AXIS]\n",
    "\n",
    "    shortcut = input\n",
    "    # 1 X 1 conv if shape is different. Else identity.\n",
    "    if stride_width > 1 or stride_height > 1 or not equal_channels:\n",
    "        shortcut = Convolution2D(nb_filter=residual_shape[CHANNEL_AXIS],\n",
    "                                 nb_row=1, nb_col=1,\n",
    "                                 subsample=(stride_width, stride_height),\n",
    "                                 init=\"he_normal\", border_mode=\"valid\",\n",
    "                                 W_regularizer=l2(0.0001))(input)\n",
    "\n",
    "    return merge([shortcut, residual], mode=\"sum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def _residual_block(block_function, nb_filter, repetitions, is_first_layer=False):\n",
    "    \"\"\"Builds a residual block with repeating bottleneck blocks.\n",
    "    \"\"\"\n",
    "    def f(input):\n",
    "        for i in range(repetitions):\n",
    "            init_subsample = (1, 1)\n",
    "            if i == 0 and not is_first_layer:\n",
    "                init_subsample = (2, 2)\n",
    "            input = block_function(nb_filter=nb_filter, init_subsample=init_subsample,\n",
    "                                   is_first_block_of_first_layer=(is_first_layer and i == 0))(input)\n",
    "        return input\n",
    "\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def basic_block(nb_filter, init_subsample=(1, 1), is_first_block_of_first_layer=False):\n",
    "    \"\"\"Basic 3 X 3 convolution blocks for use on resnets with layers <= 34.\n",
    "    Follows improved proposed scheme in http://arxiv.org/pdf/1603.05027v2.pdf\n",
    "    \"\"\"\n",
    "    def f(input):\n",
    "\n",
    "        if is_first_block_of_first_layer:\n",
    "            # don't repeat bn->relu since we just did bn->relu->maxpool\n",
    "            conv1 = Convolution2D(nb_filter=nb_filter,\n",
    "                                 nb_row=3, nb_col=3,\n",
    "                                 subsample=init_subsample,\n",
    "                                 init=\"he_normal\", border_mode=\"same\",\n",
    "                                 W_regularizer=l2(0.0001))(input)\n",
    "        else:\n",
    "            conv1 = _bn_relu_conv(nb_filter=nb_filter, nb_row=3, nb_col=3,\n",
    "                                  subsample=init_subsample)(input)\n",
    "\n",
    "        residual = _bn_relu_conv(nb_filter=nb_filter, nb_row=3, nb_col=3)(conv1)\n",
    "        return _shortcut(input, residual)\n",
    "\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def bottleneck(nb_filter, init_subsample=(1, 1), is_first_block_of_first_layer=False):\n",
    "    \"\"\"Bottleneck architecture for > 34 layer resnet.\n",
    "    Follows improved proposed scheme in http://arxiv.org/pdf/1603.05027v2.pdf\n",
    "\n",
    "    Returns:\n",
    "        A final conv layer of nb_filter * 4\n",
    "    \"\"\"\n",
    "    def f(input):\n",
    "\n",
    "        if is_first_block_of_first_layer:\n",
    "            # don't repeat bn->relu since we just did bn->relu->maxpool\n",
    "            conv_1_1 = Convolution2D(nb_filter=nb_filter,\n",
    "                                 nb_row=1, nb_col=1,\n",
    "                                 subsample=init_subsample,\n",
    "                                 init=\"he_normal\", border_mode=\"same\",\n",
    "                                 W_regularizer=l2(0.0001))(input)\n",
    "        else:\n",
    "            conv_1_1 = _bn_relu_conv(nb_filter=nb_filter, nb_row=1, nb_col=1,\n",
    "                                     subsample=init_subsample)(input)\n",
    "\n",
    "        conv_3_3 = _bn_relu_conv(nb_filter=nb_filter, nb_row=3, nb_col=3)(conv_1_1)\n",
    "        residual = _bn_relu_conv(nb_filter=nb_filter * 4, nb_row=1, nb_col=1)(conv_3_3)\n",
    "        return _shortcut(input, residual)\n",
    "\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def _handle_dim_ordering():\n",
    "    global ROW_AXIS\n",
    "    global COL_AXIS\n",
    "    global CHANNEL_AXIS\n",
    "    if K.image_dim_ordering() == 'tf':\n",
    "        ROW_AXIS = 1\n",
    "        COL_AXIS = 2\n",
    "        CHANNEL_AXIS = 3\n",
    "    else:\n",
    "        CHANNEL_AXIS = 1\n",
    "        ROW_AXIS = 2\n",
    "        COL_AXIS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def _get_block(identifier):\n",
    "    if isinstance(identifier, six.string_types):\n",
    "        res = globals().get(identifier)\n",
    "        if not res:\n",
    "            raise ValueError('Invalid {}'.format(identifier))\n",
    "        return res\n",
    "    return identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class ResnetBuilder(object):\n",
    "    @staticmethod\n",
    "    def build(input_shape, num_outputs, block_fn, repetitions):\n",
    "        \"\"\"Builds a custom ResNet like architecture.\n",
    "\n",
    "        Args:\n",
    "            input_shape: The input shape in the form (nb_channels, nb_rows, nb_cols)\n",
    "            num_outputs: The number of outputs at final softmax layer\n",
    "            block_fn: The block function to use. This is either `basic_block` or `bottleneck`.\n",
    "                The original paper used basic_block for layers < 50\n",
    "            repetitions: Number of repetitions of various block units.\n",
    "                At each block unit, the number of filters are doubled and the input size is halved\n",
    "\n",
    "        Returns:\n",
    "            The keras `Model`.\n",
    "        \"\"\"\n",
    "        _handle_dim_ordering()\n",
    "        if len(input_shape) != 3:\n",
    "            raise Exception(\"Input shape should be a tuple (nb_channels, nb_rows, nb_cols)\")\n",
    "\n",
    "        # Permute dimension order if necessary\n",
    "        if K.image_dim_ordering() == 'tf':\n",
    "            input_shape = (input_shape[1], input_shape[2], input_shape[0])\n",
    "\n",
    "        # Load function from str if needed.\n",
    "        block_fn = _get_block(block_fn)\n",
    "\n",
    "        input = Input(shape=input_shape)\n",
    "        conv1 = _conv_bn_relu(nb_filter=64, nb_row=7, nb_col=7, subsample=(2, 2))(input)\n",
    "        pool1 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), border_mode=\"same\")(conv1)\n",
    "\n",
    "        block = pool1\n",
    "        nb_filter = 64\n",
    "        for i, r in enumerate(repetitions):\n",
    "            block = _residual_block(block_fn, nb_filter=nb_filter, repetitions=r, is_first_layer=(i == 0))(block)\n",
    "            nb_filter *= 2\n",
    "\n",
    "        # Last activation\n",
    "        block = _bn_relu(block)\n",
    "\n",
    "        block_norm = BatchNormalization(mode=0, axis=CHANNEL_AXIS)(block)\n",
    "        block_output = Activation(\"relu\")(block_norm)\n",
    "\n",
    "        # Classifier block\n",
    "        block_shape = K.int_shape(block)\n",
    "        pool2 = AveragePooling2D(pool_size=(block_shape[ROW_AXIS], block_shape[COL_AXIS]),\n",
    "                                 strides=(1, 1))(block_output)\n",
    "        flatten1 = Flatten()(pool2)\n",
    "        dense = Dense(output_dim=num_outputs, init=\"he_normal\", activation=\"softmax\")(flatten1)\n",
    "        #dense = Dense(output_dim=num_outputs, W_regularizer=l2(0.01), init=\"he_normal\", activation=\"linear\")(flatten1)\n",
    "\n",
    "        model = Model(input=input, output=dense)\n",
    "        return model\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_test(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, basic_block, [1, 1, 1, 1])\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_18(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, basic_block, [2, 2, 2, 2])\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_34(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, basic_block, [3, 4, 6, 3])\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_50(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 4, 6, 3])\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_101(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 4, 23, 3])\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_152(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 8, 36, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Batch Generator for model fit_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def batch_generator_train(files, batch_size):\n",
    "    number_of_batches = np.ceil(len(files)/batch_size)\n",
    "    counter = 0\n",
    "    random.shuffle(files)\n",
    "    while True:\n",
    "        batch_files = files[batch_size*counter:batch_size*(counter+1)]\n",
    "        image_list = []\n",
    "        mask_list = []\n",
    "        for f in batch_files:\n",
    "            image = cv2.imread(f)\n",
    "            image = cv2.resize(image, conf['image_shape'])\n",
    "\n",
    "            if \"Type_1\" in f:\n",
    "                mask = [1, 0, 0]\n",
    "            elif \"Type_2\" in f:\n",
    "                mask = [0, 1, 0]\n",
    "            elif \"Type_3\" in f:\n",
    "                mask = [0, 0, 1]\n",
    "            else:\n",
    "                raise RuntimeError(\"Bad file name, couldn't determine cancer type\")\n",
    "\n",
    "            image_list.append(image)\n",
    "            mask_list.append(mask)\n",
    "        counter += 1\n",
    "        image_list = np.array(image_list)\n",
    "        mask_list = np.array(mask_list)\n",
    "\n",
    "        yield image_list, mask_list\n",
    "\n",
    "        if counter == number_of_batches:\n",
    "            random.shuffle(files)\n",
    "            counter = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Hardcoded paths to training files. Note that \"additional\" has been renamed to \"add01\" since the path lengths must be the same for substring extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# file paths to training and additional samples\n",
    "gFilesBase = \"../data/preprocess1\"\n",
    "filepaths = []\n",
    "filepaths.append( join(gFilesBase, \"train/Type_1/\") )\n",
    "filepaths.append( join(gFilesBase, \"train/Type_2/\") )\n",
    "filepaths.append( join(gFilesBase, \"train/Type_3/\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "filepaths.append( join(gFilesBase, \"additional/AType_1/\") )\n",
    "filepaths.append( join(gFilesBase, \"additional/AType_2/\") )\n",
    "filepaths.append( join(gFilesBase, \"additional/AType_3/\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Get a list of all training files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "allFiles = []\n",
    "\n",
    "for i, filepath in enumerate(filepaths):\n",
    "    files = glob.glob(filepath + '*.jpg')\n",
    "    allFiles = allFiles + files\n",
    "\n",
    "print(len(allFiles))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Split data into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "split_point = int(round(conf['train_valid_fraction']*len(allFiles)))\n",
    "\n",
    "random.shuffle(allFiles)\n",
    "\n",
    "train_list = allFiles[:split_point]\n",
    "valid_list = allFiles[split_point:]\n",
    "print('Train patients: {}'.format(len(train_list)))\n",
    "print('Valid patients: {}'.format(len(valid_list)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def batch_generator_train2(files):\n",
    "    random.shuffle(files)\n",
    "    image_list = []\n",
    "    mask_list = []\n",
    "    for f in files:\n",
    "        image = cv2.imread(f)\n",
    "        image = cv2.resize(image, conf['image_shape'])\n",
    "\n",
    "        if \"Type_1\" in f:\n",
    "            mask = [1, 0, 0]\n",
    "        elif \"Type_2\" in f:\n",
    "            mask = [0, 1, 0]\n",
    "        elif \"Type_3\" in f:\n",
    "            mask = [0, 0, 1]\n",
    "        else:\n",
    "            raise RuntimeError(\"Bad file name, couldn't determine cancer type\")\n",
    "\n",
    "        image_list.append(image)\n",
    "        mask_list.append(mask)\n",
    "\n",
    "    image_list = np.array(image_list)\n",
    "    mask_list = np.array(mask_list)\n",
    "    return (image_list, mask_list)\n",
    "\n",
    "def GetDataFromFileLists(trainList, validList):\n",
    "    (X_train, Y_train) = batch_generator_train2(trainList)\n",
    "    (X_valid, Y_valid) = batch_generator_train2(validList)\n",
    "    return (X_train, Y_train), (X_valid, Y_valid)\n",
    "            \n",
    "           \n",
    "(X_train, Y_train), (X_valid, Y_valid) = GetDataFromFileLists(train_list, valid_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Testing model generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Create and compile model...')\n",
    "\n",
    "nb_classes = 3\n",
    "img_rows, img_cols = conf['image_shape'][1], conf['image_shape'][0]\n",
    "img_channels = 3\n",
    "\n",
    "model = ResnetBuilder.build_resnet_34((img_channels, img_rows, img_cols), nb_classes)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#model.compile(loss='hinge',optimizer='adadelta',metrics=['accuracy'])\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=conf['patience'], verbose=1),\n",
    "]#    ModelCheckpoint('cervical_best.hdf5', monitor='val_loss', save_best_only=True, verbose=0),\n",
    "#]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1), cooldown=0, patience=5, min_lr=0.5e-6)\n",
    "early_stopper = EarlyStopping(min_delta=0.00001, patience=10)\n",
    "csv_logger = CSVLogger('resnet34_kcc3_12.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "conf['nb_epoch'] = 200\n",
    "\n",
    "print(\"Fitting model...\")\n",
    "if not conf['data_augmentation']:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(X_train, Y_train,\n",
    "              batch_size=batch_size,\n",
    "              nb_epoch=nb_epoch,\n",
    "              validation_data=(X_test, Y_test),\n",
    "              shuffle=True,\n",
    "              verbose=2,\n",
    "              callbacks=[lr_reducer, early_stopper, csv_logger])\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=180,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.15,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.15,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "    \n",
    "    # Compute quantities required for featurewise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(X_train)\n",
    "    \n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    model.fit_generator(datagen.flow(X_train, Y_train, batch_size=conf['batch_size']),\n",
    "                        steps_per_epoch=X_train.shape[0] // conf['batch_size'],\n",
    "                        validation_data=(X_valid, Y_valid),\n",
    "                        epochs=conf['nb_epoch'], verbose=2, max_q_size=100,\n",
    "                        callbacks=[lr_reducer, early_stopper, csv_logger])\n",
    "\n",
    "model.save(\"../models/resnet34_subm12.h5\")\n",
    "print(\"...Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Create submission files with prediction for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sample_subm = pd.read_csv(\"../data/sample_submission.csv\")\n",
    "ids = sample_subm['image_name'].values\n",
    "\n",
    "print(\"Making predictions...\")\n",
    "for id in ids:\n",
    "#    print('Predict for image {}'.format(id))\n",
    "    files = glob.glob( join(gFilesBase, \"test/unknown/\" + id) )\n",
    "    image_list = []\n",
    "    for f in files:\n",
    "        image = cv2.imread(f)\n",
    "        image = cv2.resize(image, conf['image_shape'])\n",
    "        image_list.append(image)\n",
    "        \n",
    "    image_list = np.array(image_list)\n",
    "\n",
    "    predictions = model.predict(image_list, verbose=0, batch_size=1)\n",
    "\n",
    "    sample_subm.loc[sample_subm['image_name'] == id, 'Type_1'] = predictions[0,0]\n",
    "    sample_subm.loc[sample_subm['image_name'] == id, 'Type_2'] = predictions[0,1]\n",
    "    sample_subm.loc[sample_subm['image_name'] == id, 'Type_3'] = predictions[0,2]\n",
    "    \n",
    "sample_subm.to_csv(\"../submissions/subm12.csv\", index=False)\n",
    "\n",
    "print(\"... Done\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Model Notes:\n",
    "\n",
    "#5. \n",
    "192x192, early stopping after ~100 epochs.  First model to include (segmented) additional training data\n",
    "loss: 0.8371 - acc: 0.6851 - val_loss: 1.0162 - val_acc: 0.6023\n",
    "\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=180,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=True)  # randomly flip images\n",
    "\n",
    "\n",
    "#6. \n",
    "58s - loss: 0.8437 - acc: 0.6743 - val_loss: 9.5252 - val_acc: 0.4074\n",
    "Epoch 75/200\n",
    "\n",
    "Validation loss would not budge, killed it.\n",
    "\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=True,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=180,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=True)  # randomly flip images\n",
    "\n",
    "\n",
    "#7. \n",
    "Epoch 65/200\n",
    "33s - loss: 1.0168 - acc: 0.6604 - val_loss: 1.0923 - val_acc: 0.6297\n",
    "Stopped on its own.  Only used original training set.\n",
    "\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=True,  # apply ZCA whitening\n",
    "        rotation_range=180,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "\n",
    "#8. \n",
    "Epoch 68/200\n",
    "57s - loss: 0.8332 - acc: 0.6768 - val_loss: 0.9782 - val_acc: 0.5862\n",
    "Using augmented training set, otherwise same as #7\n",
    "\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=True,  # apply ZCA whitening\n",
    "        rotation_range=180,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "\n",
    "#9. \n",
    "Epoch 47/200\n",
    "33s - loss: 0.9996 - acc: 0.6944 - val_loss: 1.4574 - val_acc: 0.4622\n",
    "Stopped on its own.  Only used original training set.\n",
    "\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=True,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=True,  # apply ZCA whitening\n",
    "        rotation_range=180,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "\n",
    "#10. \n",
    "58s - loss: 0.9724 - acc: 0.7001 - val_loss: 1.1917 - val_acc: 0.5351\n",
    "Epoch 55/200\n",
    "58s - loss: 0.9849 - acc: 0.6817 - val_loss: 1.1903 - val_acc: 0.5568\n",
    "Epoch 56/200\n",
    "58s - loss: 1.0009 - acc: 0.6741 - val_loss: 1.2002 - val_acc: 0.5270\n",
    "Epoch 57/200\n",
    "58s - loss: 1.0055 - acc: 0.6826 - val_loss: 1.2418 - val_acc: 0.5243\n",
    "ResNet_50, otherwise mostly the same as #7\n",
    "\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=True,  # apply ZCA whitening\n",
    "        rotation_range=180,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.15,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.15,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "\n",
    "#11. \n",
    "98s - loss: 0.9434 - acc: 0.6249 - val_loss: 0.9867 - val_acc: 0.5919\n",
    "Epoch 56/200\n",
    "98s - loss: 0.9211 - acc: 0.6454 - val_loss: 1.0735 - val_acc: 0.5189\n",
    "Epoch 57/200\n",
    "98s - loss: 0.9314 - acc: 0.6388 - val_loss: 1.1562 - val_acc: 0.4973\n",
    "Epoch 58/200\n",
    "98s - loss: 0.9161 - acc: 0.6467 - val_loss: 1.3069 - val_acc: 0.4514\n",
    "ResNet_101, otherwise mostly the same as #7\n",
    "\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=True,  # apply ZCA whitening\n",
    "        rotation_range=180,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.15,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.15,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "\n",
    "#12. \n",
    "33s - loss: 1.0990 - acc: 0.6254 - val_loss: 1.3437 - val_acc: 0.3541\n",
    "Epoch 44/200\n",
    "33s - loss: 1.0470 - acc: 0.6574 - val_loss: 1.3389 - val_acc: 0.3243\n",
    "Epoch 45/200\n",
    "33s - loss: 1.0864 - acc: 0.6262 - val_loss: 1.3281 - val_acc: 0.3730\n",
    "Epoch 46/200\n",
    "33s - loss: 1.0384 - acc: 0.6581 - val_loss: 1.2831 - val_acc: 0.4135\n",
    "ResNet_34, otherwise identical to 10, 11\n",
    "\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=True,  # apply ZCA whitening\n",
    "        rotation_range=180,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.15,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.15,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def residual_drop(x, input_shape, output_shape, strides=(1, 1)):\n",
    "    global add_tables\n",
    "\n",
    "    nb_filter = output_shape[0]\n",
    "    conv = Convolution2D(nb_filter, 3, 3, subsample=strides,\n",
    "                         border_mode=\"same\", W_regularizer=l2(weight_decay))(x)\n",
    "    conv = BatchNormalization(axis=1)(conv)\n",
    "    conv = Activation(\"relu\")(conv)\n",
    "    conv = Convolution2D(nb_filter, 3, 3,\n",
    "                         border_mode=\"same\", W_regularizer=l2(weight_decay))(conv)\n",
    "    conv = BatchNormalization(axis=1)(conv)\n",
    "\n",
    "    if strides[0] >= 2:\n",
    "        x = AveragePooling2D(strides)(x)\n",
    "\n",
    "    if (output_shape[0] - input_shape[0]) > 0:\n",
    "        pad_shape = (1,\n",
    "                     output_shape[0] - input_shape[0],\n",
    "                     output_shape[1],\n",
    "                     output_shape[2])\n",
    "        padding = K.zeros(pad_shape)\n",
    "        padding = K.repeat_elements(padding, K.shape(x)[0], axis=0)\n",
    "        x = Lambda(lambda y: K.concatenate([y, padding], axis=1),\n",
    "                   output_shape=output_shape)(x\n",
    "\n",
    "    _death_rate = K.variable(death_rate)\n",
    "    scale = K.ones_like(conv) - _death_rate\n",
    "    conv = Lambda(lambda c: K.in_test_phase(scale * c, c),\n",
    "                  output_shape=output_shape)(conv)\n",
    "\n",
    "    out = merge([conv, x], mode=\"sum\")\n",
    "    out = Activation(\"relu\")(out)\n",
    "\n",
    "    gate = K.variable(1, dtype=\"uint8\")\n",
    "    add_tables += [{\"death_rate\": _death_rate, \"gate\": gate}]\n",
    "    return Lambda(lambda tensors: K.switch(gate, tensors[0], tensors[1]),\n",
    "                  output_shape=output_shape)([out, x])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "nb_classes = 10\n",
    "nb_epoch = 500\n",
    "N = 18\n",
    "weight_decay = 1e-4\n",
    "lr_schedule = [0.5, 0.75]\n",
    "\n",
    "death_mode = \"lin_decay\"  # or uniform\n",
    "death_rate = 0.5\n",
    "\n",
    "img_rows, img_cols = 32, 32\n",
    "img_channels = 3\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "add_tables = []\n",
    "\n",
    "inputs = Input(shape=(img_channels, img_rows, img_cols))\n",
    "\n",
    "net = Convolution2D(16, 3, 3, border_mode=\"same\", W_regularizer=l2(weight_decay))(inputs)\n",
    "net = BatchNormalization(axis=1)(net)\n",
    "net = Activation(\"relu\")(net)\n",
    "\n",
    "\n",
    "\n",
    "for i in range(N):\n",
    "    net = residual_drop(net, input_shape=(16, 32, 32), output_shape=(16, 32, 32))\n",
    "\n",
    "net = residual_drop(\n",
    "    net,\n",
    "    input_shape=(16, 32, 32),\n",
    "    output_shape=(32, 16, 16),\n",
    "    strides=(2, 2)\n",
    ")\n",
    "for i in range(N - 1):\n",
    "    net = residual_drop(\n",
    "        net,\n",
    "        input_shape=(32, 16, 16),\n",
    "        output_shape=(32, 16, 16)\n",
    "    )\n",
    "\n",
    "net = residual_drop(\n",
    "    net,\n",
    "    input_shape=(32, 16, 16),\n",
    "    output_shape=(64, 8, 8),\n",
    "    strides=(2, 2)\n",
    ")\n",
    "for i in range(N - 1):\n",
    "    net = residual_drop(\n",
    "        net,\n",
    "        input_shape=(64, 8, 8),\n",
    "        output_shape=(64, 8, 8)\n",
    "    )\n",
    "\n",
    "pool = AveragePooling2D((8, 8))(net)\n",
    "flatten = Flatten()(pool)\n",
    "\n",
    "predictions = Dense(10, activation=\"softmax\", W_regularizer=l2(weight_decay))(flatten)\n",
    "model = Model(input=inputs, output=predictions)\n",
    "\n",
    "sgd = SGD(lr=0.1, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer=sgd, loss=\"categorical_crossentropy\")\n",
    "\n",
    "\n",
    "def open_all_gates():\n",
    "    for t in add_tables:\n",
    "        K.set_value(t[\"gate\"], 1)\n",
    "\n",
    "\n",
    "# setup death rate\n",
    "for i, tb in enumerate(add_tables, start=1):\n",
    "    if death_mode == \"uniform\":\n",
    "        K.set_value(tb[\"death_rate\"], death_rate)\n",
    "    elif death_mode == \"lin_decay\":\n",
    "        K.set_value(tb[\"death_rate\"], i / len(add_tables) * death_rate)\n",
    "    else:\n",
    "        raise\n",
    "\n",
    "\n",
    "class GatesUpdate(Callback):\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        open_all_gates()\n",
    "\n",
    "        rands = np.random.uniform(size=len(add_tables))\n",
    "        for t, rand in zip(add_tables, rands):\n",
    "            if rand < K.get_value(t[\"death_rate\"]):\n",
    "                K.set_value(t[\"gate\"], 0)\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        open_all_gates()  # for validation\n",
    "\n",
    "\n",
    "def schedule(epoch_idx):\n",
    "    if (epoch_idx + 1) < (nb_epoch * lr_schedule[0]):\n",
    "        return 0.1\n",
    "    elif (epoch_idx + 1) < (nb_epoch * lr_schedule[1]):\n",
    "        return 0.01\n",
    "\n",
    "    return 0.001\n",
    "\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=True,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=False,\n",
    "    rotation_range=0,\n",
    "    width_shift_range=0.,\n",
    "    height_shift_range=0.,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False)\n",
    "datagen.fit(X_train)\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=True,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=False,\n",
    "    rotation_range=0,\n",
    "    width_shift_range=0.,\n",
    "    height_shift_range=0.,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False)\n",
    "test_datagen.fit(X_test)\n",
    "\n",
    "# fit the model on the batches generated by datagen.flow()\n",
    "model.fit_generator(datagen.flow(X_train, Y_train, batch_size=batch_size, shuffle=True),\n",
    "                    samples_per_epoch=X_train.shape[0],\n",
    "                    nb_epoch=nb_epoch,\n",
    "                    validation_data=test_datagen.flow(X_test, Y_test, batch_size=batch_size),\n",
    "                    nb_val_samples=X_test.shape[0],\n",
    "                    callbacks=[GatesUpdate(), LearningRateScheduler(schedule)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[1,2,3], [4,5,6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
