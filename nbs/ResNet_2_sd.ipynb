{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Copied and modified from Rodney Thomas' posted version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import six\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import glob\n",
    "import random\n",
    "\n",
    "import os\n",
    "from os.path import join\n",
    "\n",
    "np.random.seed(2016)\n",
    "random.seed(2016)\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Activation, merge, Dense, Flatten, Lambda\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.callbacks import Callback, LearningRateScheduler\n",
    "\n",
    "from keras.layers.advanced_activations import ELU\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ReduceLROnPlateau, CSVLogger, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorConstant{3.0}\n"
     ]
    }
   ],
   "source": [
    "a = K.constant(3)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Removes autoscroll throughout process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
       "    return false;\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Residual Network Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "act_fun = \"sigmoid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Elemwise{switch,no_inplace}.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ELU()(K.constant(np.array([1,2,3,4,5])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def _bn_relu(input):\n",
    "    \"\"\"Helper to build a BN -> relu block\n",
    "    \"\"\"\n",
    "    norm = BatchNormalization(axis=CHANNEL_AXIS)(input)\n",
    "    return ELU()(norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def _conv_bn_relu(**conv_params):\n",
    "    \"\"\"Helper to build a conv -> BN -> relu block\n",
    "    \"\"\"\n",
    "    nb_filter = conv_params[\"nb_filter\"]\n",
    "    nb_row = conv_params[\"nb_row\"]\n",
    "    nb_col = conv_params[\"nb_col\"]\n",
    "    subsample = conv_params.setdefault(\"subsample\", (1, 1))\n",
    "    init = conv_params.setdefault(\"init\", \"he_normal\")\n",
    "    border_mode = conv_params.setdefault(\"border_mode\", \"same\")\n",
    "    W_regularizer = conv_params.setdefault(\"W_regularizer\", l2(1.e-4))\n",
    "\n",
    "    def f(input):\n",
    "        conv = Convolution2D(nb_filter=nb_filter, nb_row=nb_row, nb_col=nb_col, subsample=subsample,\n",
    "                             init=init, border_mode=border_mode, W_regularizer=W_regularizer)(input)\n",
    "        return _bn_relu(conv)\n",
    "\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def _bn_relu_conv(**conv_params):\n",
    "    \"\"\"Helper to build a BN -> relu -> conv block.\n",
    "    This is an improved scheme proposed in http://arxiv.org/pdf/1603.05027v2.pdf\n",
    "    \"\"\"\n",
    "    nb_filter = conv_params[\"nb_filter\"]\n",
    "    nb_row = conv_params[\"nb_row\"]\n",
    "    nb_col = conv_params[\"nb_col\"]\n",
    "    subsample = conv_params.setdefault(\"subsample\", (1,1))\n",
    "    init = conv_params.setdefault(\"init\", \"he_normal\")\n",
    "    border_mode = conv_params.setdefault(\"border_mode\", \"same\")\n",
    "    W_regularizer = conv_params.setdefault(\"W_regularizer\", l2(1.e-4))\n",
    "\n",
    "    def f(input):\n",
    "        activation = _bn_relu(input)\n",
    "        return Convolution2D(nb_filter=nb_filter, nb_row=nb_row, nb_col=nb_col, subsample=subsample,\n",
    "                             init=init, border_mode=border_mode, W_regularizer=W_regularizer)(activation)\n",
    "\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def _shortcut(input, residual):\n",
    "    \"\"\"Adds a shortcut between input and residual block and merges them with \"sum\"\n",
    "    \"\"\"\n",
    "    # Expand channels of shortcut to match residual.\n",
    "    # Stride appropriately to match residual (width, height)\n",
    "    # Should be int if network architecture is correctly configured.\n",
    "    input_shape = K.int_shape(input)\n",
    "    residual_shape = K.int_shape(residual)\n",
    "    stride_width = int(round(input_shape[ROW_AXIS] / residual_shape[ROW_AXIS]))\n",
    "    stride_height = int(round(input_shape[COL_AXIS] / residual_shape[COL_AXIS]))\n",
    "    equal_channels = input_shape[CHANNEL_AXIS] == residual_shape[CHANNEL_AXIS]\n",
    "\n",
    "    shortcut = input\n",
    "    # 1 X 1 conv if shape is different. Else identity.\n",
    "    if stride_width > 1 or stride_height > 1 or not equal_channels:\n",
    "        shortcut = Convolution2D(nb_filter=residual_shape[CHANNEL_AXIS],\n",
    "                                 nb_row=1, nb_col=1,\n",
    "                                 subsample=(stride_width, stride_height),\n",
    "                                 init=\"he_normal\", border_mode=\"valid\",\n",
    "                                 W_regularizer=l2(0.0001))(input)\n",
    "\n",
    "    return merge([shortcut, residual], mode=\"sum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def _residual_block(block_function, nb_filter, repetitions, is_first_layer=False):\n",
    "    \"\"\"Builds a residual block with repeating bottleneck blocks.\n",
    "    \"\"\"\n",
    "    def f(input):\n",
    "        for i in range(repetitions):\n",
    "            init_subsample = (1, 1)\n",
    "            if i == 0 and not is_first_layer:\n",
    "                init_subsample = (2, 2)\n",
    "            input = block_function(nb_filter=nb_filter, init_subsample=init_subsample,\n",
    "                                   is_first_block_of_first_layer=(is_first_layer and i == 0))(input)\n",
    "        return input\n",
    "\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def basic_block(nb_filter, init_subsample=(1, 1), is_first_block_of_first_layer=False):\n",
    "    \"\"\"Basic 3 X 3 convolution blocks for use on resnets with layers <= 34.\n",
    "    Follows improved proposed scheme in http://arxiv.org/pdf/1603.05027v2.pdf\n",
    "    \"\"\"\n",
    "    def f(input):\n",
    "\n",
    "        if is_first_block_of_first_layer:\n",
    "            # don't repeat bn->relu since we just did bn->relu->maxpool\n",
    "            conv1 = Convolution2D(nb_filter=nb_filter,\n",
    "                                 nb_row=3, nb_col=3,\n",
    "                                 subsample=init_subsample,\n",
    "                                 init=\"he_normal\", border_mode=\"same\",\n",
    "                                 W_regularizer=l2(0.0001))(input)\n",
    "        else:\n",
    "            conv1 = _bn_relu_conv(nb_filter=nb_filter, nb_row=3, nb_col=3,\n",
    "                                  subsample=init_subsample)(input)\n",
    "\n",
    "        residual = _bn_relu_conv(nb_filter=nb_filter, nb_row=3, nb_col=3)(conv1)\n",
    "        return _shortcut(input, residual)\n",
    "\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def bottleneck(nb_filter, init_subsample=(1, 1), is_first_block_of_first_layer=False):\n",
    "    \"\"\"Bottleneck architecture for > 34 layer resnet.\n",
    "    Follows improved proposed scheme in http://arxiv.org/pdf/1603.05027v2.pdf\n",
    "\n",
    "    Returns:\n",
    "        A final conv layer of nb_filter * 4\n",
    "    \"\"\"\n",
    "    def f(input):\n",
    "\n",
    "        if is_first_block_of_first_layer:\n",
    "            # don't repeat bn->relu since we just did bn->relu->maxpool\n",
    "            conv_1_1 = Convolution2D(nb_filter=nb_filter,\n",
    "                                 nb_row=1, nb_col=1,\n",
    "                                 subsample=init_subsample,\n",
    "                                 init=\"he_normal\", border_mode=\"same\",\n",
    "                                 W_regularizer=l2(0.0001))(input)\n",
    "        else:\n",
    "            conv_1_1 = _bn_relu_conv(nb_filter=nb_filter, nb_row=1, nb_col=1,\n",
    "                                     subsample=init_subsample)(input)\n",
    "\n",
    "        conv_3_3 = _bn_relu_conv(nb_filter=nb_filter, nb_row=3, nb_col=3)(conv_1_1)\n",
    "        residual = _bn_relu_conv(nb_filter=nb_filter * 4, nb_row=1, nb_col=1)(conv_3_3)\n",
    "        return _shortcut(input, residual)\n",
    "\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def _handle_dim_ordering():\n",
    "    global ROW_AXIS\n",
    "    global COL_AXIS\n",
    "    global CHANNEL_AXIS\n",
    "    if K.image_dim_ordering() == 'tf':\n",
    "        ROW_AXIS = 1\n",
    "        COL_AXIS = 2\n",
    "        CHANNEL_AXIS = 3\n",
    "    else:\n",
    "        CHANNEL_AXIS = 1\n",
    "        ROW_AXIS = 2\n",
    "        COL_AXIS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def _get_block(identifier):\n",
    "    if isinstance(identifier, six.string_types):\n",
    "        res = globals().get(identifier)\n",
    "        if not res:\n",
    "            raise ValueError('Invalid {}'.format(identifier))\n",
    "        return res\n",
    "    return identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class ResnetBuilder(object):\n",
    "    @staticmethod\n",
    "    def build(input_shape, num_outputs, block_fn, repetitions):\n",
    "        \"\"\"Builds a custom ResNet like architecture.\n",
    "\n",
    "        Args:\n",
    "            input_shape: The input shape in the form (nb_channels, nb_rows, nb_cols)\n",
    "            num_outputs: The number of outputs at final softmax layer\n",
    "            block_fn: The block function to use. This is either `basic_block` or `bottleneck`.\n",
    "                The original paper used basic_block for layers < 50\n",
    "            repetitions: Number of repetitions of various block units.\n",
    "                At each block unit, the number of filters are doubled and the input size is halved\n",
    "\n",
    "        Returns:\n",
    "            The keras `Model`.\n",
    "        \"\"\"\n",
    "        _handle_dim_ordering()\n",
    "        if len(input_shape) != 3:\n",
    "            raise Exception(\"Input shape should be a tuple (nb_channels, nb_rows, nb_cols)\")\n",
    "\n",
    "        # Permute dimension order if necessary\n",
    "        if K.image_dim_ordering() == 'tf':\n",
    "            input_shape = (input_shape[1], input_shape[2], input_shape[0])\n",
    "\n",
    "        # Load function from str if needed.\n",
    "        block_fn = _get_block(block_fn)\n",
    "\n",
    "        input = Input(shape=input_shape)\n",
    "        conv1 = _conv_bn_relu(nb_filter=64, nb_row=7, nb_col=7, subsample=(2, 2))(input)\n",
    "        pool1 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), border_mode=\"same\")(conv1)\n",
    "\n",
    "        block = pool1\n",
    "        nb_filter = 64\n",
    "        for i, r in enumerate(repetitions):\n",
    "            block = _residual_block(block_fn, nb_filter=nb_filter, repetitions=r, is_first_layer=(i == 0))(block)\n",
    "            nb_filter *= 2\n",
    "\n",
    "        # Last activation\n",
    "        block = _bn_relu(block)\n",
    "\n",
    "        block_norm = BatchNormalization(mode=0, axis=CHANNEL_AXIS)(block)\n",
    "        block_output = Activation(act_fun)(block_norm)\n",
    "\n",
    "        # Classifier block\n",
    "        block_shape = K.int_shape(block)\n",
    "        pool2 = AveragePooling2D(pool_size=(block_shape[ROW_AXIS], block_shape[COL_AXIS]),\n",
    "                                 strides=(1, 1))(block_output)\n",
    "        flatten1 = Flatten()(pool2)\n",
    "        dense = Dense(output_dim=num_outputs, init=\"he_normal\", activation=\"softmax\")(flatten1)\n",
    "        #dense = Dense(output_dim=num_outputs, W_regularizer=l2(0.01), init=\"he_normal\", activation=\"linear\")(flatten1)\n",
    "\n",
    "        model = Model(input=input, output=dense)\n",
    "        return model\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_test(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, basic_block, [1, 1, 1, 1])\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_18(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, basic_block, [2, 2, 2, 2])\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_34(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, basic_block, [3, 4, 6, 3])\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_50(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 4, 6, 3])\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_101(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 4, 23, 3])\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_152(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 8, 36, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Global Declarations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "conf = dict()\n",
    "\n",
    "# How many patients will be in train and validation set during training. Range: (0; 1)\n",
    "conf['train_valid_fraction'] = 0.75\n",
    "\n",
    "# Batch size for CNN [Depends on GPU and memory available]\n",
    "conf['num_layers'] = 34\n",
    "conf['batch_size'] = 100\n",
    "\n",
    "# Number of epochs for CNN training\n",
    "conf['nb_epoch'] = 1000\n",
    "\n",
    "# Early stopping. Stop training after epochs without improving on validation\n",
    "conf['stop_patience'] = 100\n",
    "conf['lr_patience'] = 50\n",
    "\n",
    "# Shape of image for CNN (Larger the better, but you need to increase CNN as well)\n",
    "#conf['image_shape'] = (4160,4128)\n",
    "#conf['image_shape'] = (2080,2064)\n",
    "#conf['image_shape'] = (1024,1024)\n",
    "conf['image_shape'] = (192, 192)\n",
    "\n",
    "conf['data_augmentation'] = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Batch Generator for model fit_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def batch_generator_train(files, batch_size):\n",
    "    number_of_batches = np.ceil(len(files)/batch_size)\n",
    "    counter = 0\n",
    "    random.shuffle(files)\n",
    "    while True:\n",
    "        batch_files = files[batch_size*counter:batch_size*(counter+1)]\n",
    "        image_list = []\n",
    "        mask_list = []\n",
    "        for f in batch_files:\n",
    "            image = cv2.imread(f)\n",
    "            image = cv2.resize(image, conf['image_shape'])\n",
    "\n",
    "            if \"Type_1\" in f:\n",
    "                mask = [1, 0, 0]\n",
    "            elif \"Type_2\" in f:\n",
    "                mask = [0, 1, 0]\n",
    "            elif \"Type_3\" in f:\n",
    "                mask = [0, 0, 1]\n",
    "            else:\n",
    "                raise RuntimeError(\"Bad file name, couldn't determine cancer type\")\n",
    "\n",
    "            image_list.append(image)\n",
    "            mask_list.append(mask)\n",
    "        counter += 1\n",
    "        image_list = np.array(image_list)\n",
    "        mask_list = np.array(mask_list)\n",
    "\n",
    "        yield image_list, mask_list\n",
    "\n",
    "        if counter == number_of_batches:\n",
    "            random.shuffle(files)\n",
    "            counter = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Hardcoded paths to training files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# file paths to training and additional samples\n",
    "gFilesBase = \"../data/preprocess1\"\n",
    "#gFilesBase = \"../data\"\n",
    "filepaths = []\n",
    "filepaths.append( join(gFilesBase, \"train/Type_1/\") )\n",
    "filepaths.append( join(gFilesBase, \"train/Type_2/\") )\n",
    "filepaths.append( join(gFilesBase, \"train/Type_3/\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#filepaths.append( join(gFilesBase, \"additional/AType_1/\") )\n",
    "#filepaths.append( join(gFilesBase, \"additional/AType_2/\") )\n",
    "#filepaths.append( join(gFilesBase, \"additional/AType_3/\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Get a list of all training files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1481\n"
     ]
    }
   ],
   "source": [
    "allFiles = []\n",
    "\n",
    "for i, filepath in enumerate(filepaths):\n",
    "    files = glob.glob(filepath + '*.jpg')\n",
    "    allFiles = allFiles + files\n",
    "\n",
    "print(len(allFiles))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Split data into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train patients: 1111\n",
      "Valid patients: 370\n"
     ]
    }
   ],
   "source": [
    "split_point = int(round(conf['train_valid_fraction']*len(allFiles)))\n",
    "\n",
    "random.shuffle(allFiles)\n",
    "\n",
    "train_list = allFiles[:split_point]\n",
    "valid_list = allFiles[split_point:]\n",
    "print('Train patients: {}'.format(len(train_list)))\n",
    "print('Valid patients: {}'.format(len(valid_list)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def batch_generator_train2(files):\n",
    "    random.shuffle(files)\n",
    "    image_list = []\n",
    "    mask_list = []\n",
    "    for f in files:\n",
    "        image = cv2.imread(f)\n",
    "        image = cv2.resize(image, conf['image_shape'])\n",
    "\n",
    "        if \"Type_1\" in f:\n",
    "            mask = [1, 0, 0]\n",
    "        elif \"Type_2\" in f:\n",
    "            mask = [0, 1, 0]\n",
    "        elif \"Type_3\" in f:\n",
    "            mask = [0, 0, 1]\n",
    "        else:\n",
    "            raise RuntimeError(\"Bad file name, couldn't determine cancer type\")\n",
    "\n",
    "        image_list.append(image)\n",
    "        mask_list.append(mask)\n",
    "\n",
    "    image_list = np.array(image_list)\n",
    "    mask_list = np.array(mask_list)\n",
    "    return (image_list, mask_list)\n",
    "\n",
    "def GetDataFromFileLists(trainList, validList):\n",
    "    (X_train, Y_train) = batch_generator_train2(trainList)\n",
    "    (X_valid, Y_valid) = batch_generator_train2(validList)\n",
    "    return (X_train, Y_train), (X_valid, Y_valid)\n",
    "            \n",
    "           \n",
    "(X_train, Y_train), (X_valid, Y_valid) = GetDataFromFileLists(train_list, valid_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'18'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the number of the next submission.  Returns as string.\n",
    "subsDir = \"../submissions\"\n",
    "def GetNextSubNum():\n",
    "    num = 2\n",
    "    while os.path.isfile( join(subsDir, \"subm\" + str(num) + \".csv\")):\n",
    "        num += 1\n",
    "    return str(num)\n",
    "\n",
    "\n",
    "GetNextSubNum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Testing model generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create and compile model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matt/Envs/keras/lib/python2.7/site-packages/ipykernel/__main__.py:14: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_initializer=\"he_normal\", padding=\"same\", strides=(2, 2), kernel_regularizer=<keras.reg..., filters=64, kernel_size=(7, 7))`\n",
      "/home/matt/Envs/keras/lib/python2.7/site-packages/ipykernel/__main__.py:30: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(padding=\"same\", strides=(2, 2), pool_size=(3, 3))`\n",
      "/home/matt/Envs/keras/lib/python2.7/site-packages/ipykernel/__main__.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_initializer=\"he_normal\", padding=\"same\", strides=(1, 1), kernel_regularizer=<keras.reg..., filters=64, kernel_size=(1, 1))`\n",
      "/home/matt/Envs/keras/lib/python2.7/site-packages/ipykernel/__main__.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_initializer=\"he_normal\", padding=\"same\", strides=(1, 1), kernel_regularizer=<keras.reg..., filters=64, kernel_size=(3, 3))`\n",
      "/home/matt/Envs/keras/lib/python2.7/site-packages/ipykernel/__main__.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_initializer=\"he_normal\", padding=\"same\", strides=(1, 1), kernel_regularizer=<keras.reg..., filters=256, kernel_size=(1, 1))`\n",
      "/home/matt/Envs/keras/lib/python2.7/site-packages/ipykernel/__main__.py:20: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_initializer=\"he_normal\", padding=\"valid\", strides=(1, 1), kernel_regularizer=<keras.reg..., filters=256, kernel_size=(1, 1))`\n",
      "/home/matt/Envs/keras/lib/python2.7/site-packages/ipykernel/__main__.py:22: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/home/matt/Envs/keras/lib/python2.7/site-packages/ipykernel/__main__.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_initializer=\"he_normal\", padding=\"same\", strides=(2, 2), kernel_regularizer=<keras.reg..., filters=128, kernel_size=(1, 1))`\n",
      "/home/matt/Envs/keras/lib/python2.7/site-packages/ipykernel/__main__.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_initializer=\"he_normal\", padding=\"same\", strides=(1, 1), kernel_regularizer=<keras.reg..., filters=128, kernel_size=(3, 3))`\n",
      "/home/matt/Envs/keras/lib/python2.7/site-packages/ipykernel/__main__.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_initializer=\"he_normal\", padding=\"same\", strides=(1, 1), kernel_regularizer=<keras.reg..., filters=512, kernel_size=(1, 1))`\n",
      "/home/matt/Envs/keras/lib/python2.7/site-packages/ipykernel/__main__.py:20: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_initializer=\"he_normal\", padding=\"valid\", strides=(2, 2), kernel_regularizer=<keras.reg..., filters=512, kernel_size=(1, 1))`\n",
      "/home/matt/Envs/keras/lib/python2.7/site-packages/ipykernel/__main__.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_initializer=\"he_normal\", padding=\"same\", strides=(1, 1), kernel_regularizer=<keras.reg..., filters=128, kernel_size=(1, 1))`\n",
      "/home/matt/Envs/keras/lib/python2.7/site-packages/ipykernel/__main__.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_initializer=\"he_normal\", padding=\"same\", strides=(2, 2), kernel_regularizer=<keras.reg..., filters=256, kernel_size=(1, 1))`\n",
      "/home/matt/Envs/keras/lib/python2.7/site-packages/ipykernel/__main__.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_initializer=\"he_normal\", padding=\"same\", strides=(1, 1), kernel_regularizer=<keras.reg..., filters=256, kernel_size=(3, 3))`\n",
      "/home/matt/Envs/keras/lib/python2.7/site-packages/ipykernel/__main__.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_initializer=\"he_normal\", padding=\"same\", strides=(1, 1), kernel_regularizer=<keras.reg..., filters=1024, kernel_size=(1, 1))`\n",
      "/home/matt/Envs/keras/lib/python2.7/site-packages/ipykernel/__main__.py:20: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_initializer=\"he_normal\", padding=\"valid\", strides=(2, 2), kernel_regularizer=<keras.reg..., filters=1024, kernel_size=(1, 1))`\n",
      "/home/matt/Envs/keras/lib/python2.7/site-packages/ipykernel/__main__.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_initializer=\"he_normal\", padding=\"same\", strides=(2, 2), kernel_regularizer=<keras.reg..., filters=512, kernel_size=(1, 1))`\n",
      "/home/matt/Envs/keras/lib/python2.7/site-packages/ipykernel/__main__.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_initializer=\"he_normal\", padding=\"same\", strides=(1, 1), kernel_regularizer=<keras.reg..., filters=512, kernel_size=(3, 3))`\n",
      "/home/matt/Envs/keras/lib/python2.7/site-packages/ipykernel/__main__.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_initializer=\"he_normal\", padding=\"same\", strides=(1, 1), kernel_regularizer=<keras.reg..., filters=2048, kernel_size=(1, 1))`\n",
      "/home/matt/Envs/keras/lib/python2.7/site-packages/ipykernel/__main__.py:20: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_initializer=\"he_normal\", padding=\"valid\", strides=(2, 2), kernel_regularizer=<keras.reg..., filters=2048, kernel_size=(1, 1))`\n",
      "/home/matt/Envs/keras/lib/python2.7/site-packages/ipykernel/__main__.py:41: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization(axis=3)`\n",
      "/home/matt/Envs/keras/lib/python2.7/site-packages/ipykernel/__main__.py:49: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=3, activation=\"softmax\", kernel_initializer=\"he_normal\")`\n",
      "/home/matt/Envs/keras/lib/python2.7/site-packages/ipykernel/__main__.py:52: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Softmax.0, inputs=elu_3/inpu...)`\n"
     ]
    }
   ],
   "source": [
    "print('Create and compile model...')\n",
    "\n",
    "nb_classes = 3\n",
    "img_rows, img_cols = conf['image_shape'][1], conf['image_shape'][0]\n",
    "img_channels = 3\n",
    "\n",
    "if conf['num_layers'] == 18:\n",
    "    model = ResnetBuilder.build_resnet_18((img_channels, img_rows, img_cols), nb_classes)\n",
    "elif conf['num_layers'] == 34:\n",
    "    model = ResnetBuilder.build_resnet_34((img_channels, img_rows, img_cols), nb_classes)\n",
    "elif conf['num_layers'] == 50:\n",
    "    model = ResnetBuilder.build_resnet_50((img_channels, img_rows, img_cols), nb_classes)\n",
    "elif conf['num_layers'] == 101:\n",
    "    model = ResnetBuilder.build_resnet_101((img_channels, img_rows, img_cols), nb_classes)\n",
    "elif conf['num_layers'] == 152:\n",
    "    model = ResnetBuilder.build_resnet_152((img_channels, img_rows, img_cols), nb_classes)\n",
    "else:\n",
    "    raise RuntimeError(\"Invalid number of layers\")\n",
    "    \n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#model.compile(loss='hinge',optimizer='adadelta',metrics=['accuracy'])\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=conf['stop_patience'], verbose=1),\n",
    "]#    ModelCheckpoint('cervical_best.hdf5', monitor='val_loss', save_best_only=True, verbose=0),\n",
    "#]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1), cooldown=0, patience=conf['lr_patience'], min_lr=0.5e-6)\n",
    "early_stopper = EarlyStopping(min_delta=0.00001, patience=conf['stop_patience'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "loggerStr = \"resnet_\" + str(conf['num_layers']) + \"kcc3_\" + GetNextSubNum() + \".csv\"\n",
    "csv_logger = CSVLogger(loggerStr)\n",
    "\n",
    "print(\"Fitting model...\")\n",
    "if not conf['data_augmentation']:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(X_train, Y_train,\n",
    "              batch_size=batch_size,\n",
    "              nb_epoch=nb_epoch,\n",
    "              validation_data=(X_test, Y_test),\n",
    "              shuffle=True,\n",
    "              verbose=2,\n",
    "              callbacks=[lr_reducer, early_stopper, csv_logger])\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=180,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.15,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.15,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "    \n",
    "    # Compute quantities required for featurewise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(X_train)\n",
    "    \n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    model.fit_generator(datagen.flow(X_train, Y_train, batch_size=conf['batch_size']),\n",
    "                        steps_per_epoch=X_train.shape[0] // conf['batch_size'],\n",
    "                        validation_data=(X_valid, Y_valid),\n",
    "                        epochs=conf['nb_epoch'], verbose=2, max_q_size=100,\n",
    "                        callbacks=[lr_reducer, early_stopper, csv_logger])\n",
    "\n",
    "modelSaveStr = \"../models/resnet\" + str(conf['num_layers']) + \"_subm\" + GetNextSubNum() + \"_final.h5\"\n",
    "model.save(modelSaveStr)\n",
    "print(\"...Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Create submission files with prediction for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n",
      "... Done\n"
     ]
    }
   ],
   "source": [
    "sample_subm = pd.read_csv(\"../data/sample_submission.csv\")\n",
    "ids = sample_subm['image_name'].values\n",
    "\n",
    "print(\"Making predictions...\")\n",
    "for id in ids:\n",
    "#    print('Predict for image {}'.format(id))\n",
    "    files = glob.glob( join(gFilesBase, \"test/unknown/\" + id) )\n",
    "    image_list = []\n",
    "    for f in files:\n",
    "        image = cv2.imread(f)\n",
    "        image = cv2.resize(image, conf['image_shape'])\n",
    "        image_list.append(image)\n",
    "        \n",
    "    image_list = np.array(image_list)\n",
    "\n",
    "    predictions = model.predict(image_list, verbose=0, batch_size=1)\n",
    "\n",
    "    sample_subm.loc[sample_subm['image_name'] == id, 'Type_1'] = predictions[0,0]\n",
    "    sample_subm.loc[sample_subm['image_name'] == id, 'Type_2'] = predictions[0,1]\n",
    "    sample_subm.loc[sample_subm['image_name'] == id, 'Type_3'] = predictions[0,2]\n",
    "    \n",
    "submStr = \"../submissions/subm\" + GetNextSubNum() + \".csv\"\n",
    "sample_subm.to_csv(submStr, index=False)\n",
    "\n",
    "print(\"... Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'modelSaveStr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-75cd2a415574>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodelSaveStr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'modelSaveStr' is not defined"
     ]
    }
   ],
   "source": [
    "modelSaveStr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_6 (InputLayer)             (None, 192, 192, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)               (None, 96, 96, 64)    9472                                         \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNor (None, 96, 96, 64)    256                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_72 (Activation)       (None, 96, 96, 64)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)   (None, 48, 48, 64)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)               (None, 48, 48, 64)    36928                                        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNor (None, 48, 48, 64)    256                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_73 (Activation)       (None, 48, 48, 64)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)               (None, 48, 48, 64)    36928                                        \n",
      "____________________________________________________________________________________________________\n",
      "merge_33 (Merge)                 (None, 48, 48, 64)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNor (None, 48, 48, 64)    256                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_74 (Activation)       (None, 48, 48, 64)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)               (None, 48, 48, 64)    36928                                        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNor (None, 48, 48, 64)    256                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_75 (Activation)       (None, 48, 48, 64)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)               (None, 48, 48, 64)    36928                                        \n",
      "____________________________________________________________________________________________________\n",
      "merge_34 (Merge)                 (None, 48, 48, 64)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNor (None, 48, 48, 64)    256                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_76 (Activation)       (None, 48, 48, 64)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)               (None, 48, 48, 64)    36928                                        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNor (None, 48, 48, 64)    256                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_77 (Activation)       (None, 48, 48, 64)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)               (None, 48, 48, 64)    36928                                        \n",
      "____________________________________________________________________________________________________\n",
      "merge_35 (Merge)                 (None, 48, 48, 64)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNor (None, 48, 48, 64)    256                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_78 (Activation)       (None, 48, 48, 64)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)               (None, 24, 24, 128)   73856                                        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNor (None, 24, 24, 128)   512                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_79 (Activation)       (None, 24, 24, 128)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)               (None, 24, 24, 128)   8320                                         \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)               (None, 24, 24, 128)   147584                                       \n",
      "____________________________________________________________________________________________________\n",
      "merge_36 (Merge)                 (None, 24, 24, 128)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNor (None, 24, 24, 128)   512                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_80 (Activation)       (None, 24, 24, 128)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)               (None, 24, 24, 128)   147584                                       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNor (None, 24, 24, 128)   512                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_81 (Activation)       (None, 24, 24, 128)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)               (None, 24, 24, 128)   147584                                       \n",
      "____________________________________________________________________________________________________\n",
      "merge_37 (Merge)                 (None, 24, 24, 128)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNor (None, 24, 24, 128)   512                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_82 (Activation)       (None, 24, 24, 128)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)               (None, 24, 24, 128)   147584                                       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNor (None, 24, 24, 128)   512                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_83 (Activation)       (None, 24, 24, 128)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)               (None, 24, 24, 128)   147584                                       \n",
      "____________________________________________________________________________________________________\n",
      "merge_38 (Merge)                 (None, 24, 24, 128)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNor (None, 24, 24, 128)   512                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_84 (Activation)       (None, 24, 24, 128)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)               (None, 24, 24, 128)   147584                                       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNor (None, 24, 24, 128)   512                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_85 (Activation)       (None, 24, 24, 128)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)               (None, 24, 24, 128)   147584                                       \n",
      "____________________________________________________________________________________________________\n",
      "merge_39 (Merge)                 (None, 24, 24, 128)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNor (None, 24, 24, 128)   512                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_86 (Activation)       (None, 24, 24, 128)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)               (None, 12, 12, 256)   295168                                       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNor (None, 12, 12, 256)   1024                                         \n",
      "____________________________________________________________________________________________________\n",
      "activation_87 (Activation)       (None, 12, 12, 256)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)               (None, 12, 12, 256)   33024                                        \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)               (None, 12, 12, 256)   590080                                       \n",
      "____________________________________________________________________________________________________\n",
      "merge_40 (Merge)                 (None, 12, 12, 256)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNor (None, 12, 12, 256)   1024                                         \n",
      "____________________________________________________________________________________________________\n",
      "activation_88 (Activation)       (None, 12, 12, 256)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)               (None, 12, 12, 256)   590080                                       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNor (None, 12, 12, 256)   1024                                         \n",
      "____________________________________________________________________________________________________\n",
      "activation_89 (Activation)       (None, 12, 12, 256)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)               (None, 12, 12, 256)   590080                                       \n",
      "____________________________________________________________________________________________________\n",
      "merge_41 (Merge)                 (None, 12, 12, 256)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNor (None, 12, 12, 256)   1024                                         \n",
      "____________________________________________________________________________________________________\n",
      "activation_90 (Activation)       (None, 12, 12, 256)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)               (None, 12, 12, 256)   590080                                       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNor (None, 12, 12, 256)   1024                                         \n",
      "____________________________________________________________________________________________________\n",
      "activation_91 (Activation)       (None, 12, 12, 256)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)               (None, 12, 12, 256)   590080                                       \n",
      "____________________________________________________________________________________________________\n",
      "merge_42 (Merge)                 (None, 12, 12, 256)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNor (None, 12, 12, 256)   1024                                         \n",
      "____________________________________________________________________________________________________\n",
      "activation_92 (Activation)       (None, 12, 12, 256)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)               (None, 12, 12, 256)   590080                                       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNor (None, 12, 12, 256)   1024                                         \n",
      "____________________________________________________________________________________________________\n",
      "activation_93 (Activation)       (None, 12, 12, 256)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)              (None, 12, 12, 256)   590080                                       \n",
      "____________________________________________________________________________________________________\n",
      "merge_43 (Merge)                 (None, 12, 12, 256)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNor (None, 12, 12, 256)   1024                                         \n",
      "____________________________________________________________________________________________________\n",
      "activation_94 (Activation)       (None, 12, 12, 256)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)              (None, 12, 12, 256)   590080                                       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNor (None, 12, 12, 256)   1024                                         \n",
      "____________________________________________________________________________________________________\n",
      "activation_95 (Activation)       (None, 12, 12, 256)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)              (None, 12, 12, 256)   590080                                       \n",
      "____________________________________________________________________________________________________\n",
      "merge_44 (Merge)                 (None, 12, 12, 256)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNor (None, 12, 12, 256)   1024                                         \n",
      "____________________________________________________________________________________________________\n",
      "activation_96 (Activation)       (None, 12, 12, 256)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)              (None, 12, 12, 256)   590080                                       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNor (None, 12, 12, 256)   1024                                         \n",
      "____________________________________________________________________________________________________\n",
      "activation_97 (Activation)       (None, 12, 12, 256)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)              (None, 12, 12, 256)   590080                                       \n",
      "____________________________________________________________________________________________________\n",
      "merge_45 (Merge)                 (None, 12, 12, 256)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNor (None, 12, 12, 256)   1024                                         \n",
      "____________________________________________________________________________________________________\n",
      "activation_98 (Activation)       (None, 12, 12, 256)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)              (None, 6, 6, 512)     1180160                                      \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNor (None, 6, 6, 512)     2048                                         \n",
      "____________________________________________________________________________________________________\n",
      "activation_99 (Activation)       (None, 6, 6, 512)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)              (None, 6, 6, 512)     131584                                       \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)              (None, 6, 6, 512)     2359808                                      \n",
      "____________________________________________________________________________________________________\n",
      "merge_46 (Merge)                 (None, 6, 6, 512)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchNo (None, 6, 6, 512)     2048                                         \n",
      "____________________________________________________________________________________________________\n",
      "activation_100 (Activation)      (None, 6, 6, 512)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)              (None, 6, 6, 512)     2359808                                      \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchNo (None, 6, 6, 512)     2048                                         \n",
      "____________________________________________________________________________________________________\n",
      "activation_101 (Activation)      (None, 6, 6, 512)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)              (None, 6, 6, 512)     2359808                                      \n",
      "____________________________________________________________________________________________________\n",
      "merge_47 (Merge)                 (None, 6, 6, 512)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchNo (None, 6, 6, 512)     2048                                         \n",
      "____________________________________________________________________________________________________\n",
      "activation_102 (Activation)      (None, 6, 6, 512)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)              (None, 6, 6, 512)     2359808                                      \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchNo (None, 6, 6, 512)     2048                                         \n",
      "____________________________________________________________________________________________________\n",
      "activation_103 (Activation)      (None, 6, 6, 512)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)              (None, 6, 6, 512)     2359808                                      \n",
      "____________________________________________________________________________________________________\n",
      "merge_48 (Merge)                 (None, 6, 6, 512)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchNo (None, 6, 6, 512)     2048                                         \n",
      "____________________________________________________________________________________________________\n",
      "activation_104 (Activation)      (None, 6, 6, 512)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchNo (None, 6, 6, 512)     2048                                         \n",
      "____________________________________________________________________________________________________\n",
      "activation_105 (Activation)      (None, 6, 6, 512)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePool (None, 1, 1, 512)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)              (None, 512)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 3)             1539                                         \n",
      "====================================================================================================\n",
      "Total params: 21,310,211.0\n",
      "Trainable params: 21,293,955.0\n",
      "Non-trainable params: 16,256.0\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "lr_schedule = [0.5, 0.75]\n",
    "\n",
    "def residual_drop(x, input_shape, output_shape, strides=(1, 1)):\n",
    "    global add_tables\n",
    "\n",
    "    nb_filter = output_shape[0]\n",
    "    conv = Convolution2D(nb_filter, 3, 3, subsample=strides,\n",
    "                         border_mode=\"same\", W_regularizer=l2(weight_decay))(x)\n",
    "    conv = BatchNormalization(axis=1)(conv)\n",
    "    conv = Activation(\"relu\")(conv)\n",
    "    conv = Convolution2D(nb_filter, 3, 3,\n",
    "                         border_mode=\"same\", W_regularizer=l2(weight_decay))(conv)\n",
    "    conv = BatchNormalization(axis=1)(conv)\n",
    "\n",
    "    if strides[0] >= 2:\n",
    "        x = AveragePooling2D(strides)(x)\n",
    "\n",
    "    if (output_shape[0] - input_shape[0]) > 0:\n",
    "        pad_shape = (1,\n",
    "                     output_shape[0] - input_shape[0],\n",
    "                     output_shape[1],\n",
    "                     output_shape[2])\n",
    "        padding = K.zeros(pad_shape)\n",
    "        padding = K.repeat_elements(padding, K.shape(x)[0], axis=0)\n",
    "        x = Lambda(lambda y: K.concatenate([y, padding], axis=1),\n",
    "                   output_shape=output_shape)(x)\n",
    "\n",
    "    _death_rate = K.variable(death_rate)\n",
    "    scale = K.ones_like(conv) - _death_rate\n",
    "    conv = Lambda(lambda c: K.in_test_phase(scale * c, c),\n",
    "                  output_shape=output_shape)(conv)\n",
    "\n",
    "    out = merge([conv, x], mode=\"sum\")\n",
    "    out = Activation(\"relu\")(out)\n",
    "\n",
    "    gate = K.variable(1, dtype=\"uint8\")\n",
    "    add_tables += [{\"death_rate\": _death_rate, \"gate\": gate}]\n",
    "    return Lambda(lambda tensors: K.switch(gate, tensors[0], tensors[1]),\n",
    "                  output_shape=output_shape)([out, x])\n",
    "\n",
    "\n",
    "def open_all_gates():\n",
    "    for t in add_tables:\n",
    "        K.set_value(t[\"gate\"], 1)\n",
    "\n",
    "\n",
    "class GatesUpdate(Callback):\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        open_all_gates()\n",
    "\n",
    "        rands = np.random.uniform(size=len(add_tables))\n",
    "        for t, rand in zip(add_tables, rands):\n",
    "            if rand < K.get_value(t[\"death_rate\"]):\n",
    "                K.set_value(t[\"gate\"], 0)\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        open_all_gates()  # for validation\n",
    "\n",
    "\n",
    "def schedule(epoch_idx):\n",
    "    if (epoch_idx + 1) < (conf['nb_epoch'] * lr_schedule[0]):\n",
    "        return 0.1\n",
    "    elif (epoch_idx + 1) < (conf['nb_epoch'] * lr_schedule[1]):\n",
    "        return 0.01\n",
    "\n",
    "    return 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'weight_decay' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-145-4428372dfa46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConvolution2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mborder_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"same\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ml2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mActivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'weight_decay' is not defined"
     ]
    }
   ],
   "source": [
    "#N = 18\n",
    "#weight_decay = 1e-4\n",
    "\n",
    "death_mode = \"lin_decay\"  # or uniform\n",
    "death_rate = 0.5\n",
    "\n",
    "add_tables = []\n",
    "\n",
    "inputs = Input(shape=(img_channels, img_rows, img_cols))\n",
    "\n",
    "net = Convolution2D(16, 3, 3, border_mode=\"same\", W_regularizer=l2(weight_decay))(inputs)\n",
    "net = BatchNormalization(axis=1)(net)\n",
    "net = Activation(\"relu\")(net)\n",
    "\n",
    "\n",
    "\n",
    "for i in range(N):\n",
    "    net = residual_drop(net, input_shape=(16, 32, 32), output_shape=(16, 32, 32))\n",
    "\n",
    "net = residual_drop(\n",
    "    net,\n",
    "    input_shape=(16, 32, 32),\n",
    "    output_shape=(32, 16, 16),\n",
    "    strides=(2, 2)\n",
    ")\n",
    "for i in range(N - 1):\n",
    "    net = residual_drop(\n",
    "        net,\n",
    "        input_shape=(32, 16, 16),\n",
    "        output_shape=(32, 16, 16)\n",
    "    )\n",
    "\n",
    "net = residual_drop(\n",
    "    net,\n",
    "    input_shape=(32, 16, 16),\n",
    "    output_shape=(64, 8, 8),\n",
    "    strides=(2, 2)\n",
    ")\n",
    "for i in range(N - 1):\n",
    "    net = residual_drop(\n",
    "        net,\n",
    "        input_shape=(64, 8, 8),\n",
    "        output_shape=(64, 8, 8)\n",
    "    )\n",
    "\n",
    "pool = AveragePooling2D((8, 8))(net)\n",
    "flatten = Flatten()(pool)\n",
    "\n",
    "predictions = Dense(10, activation=\"softmax\", W_regularizer=l2(weight_decay))(flatten)\n",
    "model = Model(input=inputs, output=predictions)\n",
    "\n",
    "sgd = SGD(lr=0.1, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer=sgd, loss=\"categorical_crossentropy\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=True,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=False,\n",
    "    rotation_range=0,\n",
    "    width_shift_range=0.,\n",
    "    height_shift_range=0.,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False)\n",
    "datagen.fit(X_train)\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=True,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=False,\n",
    "    rotation_range=0,\n",
    "    width_shift_range=0.,\n",
    "    height_shift_range=0.,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False)\n",
    "test_datagen.fit(X_test)\n",
    "\n",
    "# fit the model on the batches generated by datagen.flow()\n",
    "model.fit_generator(datagen.flow(X_train, Y_train, batch_size=batch_size, shuffle=True),\n",
    "                    samples_per_epoch=X_train.shape[0],\n",
    "                    nb_epoch=nb_epoch,\n",
    "                    validation_data=test_datagen.flow(X_test, Y_test, batch_size=batch_size),\n",
    "                    nb_val_samples=X_test.shape[0],\n",
    "                    callbacks=[GatesUpdate(), LearningRateScheduler(schedule)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1), cooldown=0, patience=conf['lr_patience'], min_lr=0.5e-6)\n",
    "early_stopper = EarlyStopping(min_delta=0.00001, patience=conf['stop_patience'])\n",
    "csv_logger = CSVLogger('resnet34_kcc3_15.csv')\n",
    "\n",
    "\"\"\"\n",
    "# setup death rate\n",
    "for i, tb in enumerate(add_tables, start=1):\n",
    "    if death_mode == \"uniform\":\n",
    "        K.set_value(tb[\"death_rate\"], death_rate)\n",
    "    elif death_mode == \"lin_decay\":\n",
    "        K.set_value(tb[\"death_rate\"], i / len(add_tables) * death_rate)\n",
    "    else:\n",
    "        raise\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conf['nb_epoch'] = 200\n",
    "conf['data_augmentation'] = True\n",
    "\n",
    "print(\"Fitting model...\")\n",
    "if not conf['data_augmentation']:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(X_train, Y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=conf['nb_epoch'],\n",
    "              validation_data=(X_test, Y_test),\n",
    "              shuffle=True,\n",
    "              verbose=2,\n",
    "              callbacks=[lr_reducer, early_stopper, csv_logger])\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=180,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.15,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.15,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "    \n",
    "    # Compute quantities required for featurewise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(X_train)\n",
    "    \n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    model.fit_generator(datagen.flow(X_train, Y_train, batch_size=conf['batch_size']),\n",
    "                        steps_per_epoch=X_train.shape[0] // conf['batch_size'],\n",
    "                        validation_data=(X_valid, Y_valid),\n",
    "                        epochs=conf['nb_epoch'], verbose=2, max_q_size=100,\n",
    "                        callbacks=[lr_reducer, early_stopper, csv_logger, GatesUpdate(), LearningRateScheduler(schedule)])\n",
    "\n",
    "model.save(\"../models/resnet34_subm15.h5\")\n",
    "print(\"...Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
